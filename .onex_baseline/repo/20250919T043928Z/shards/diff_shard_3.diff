diff --git a/src/omnimemory/models/foundation/model_progress_summary.py b/src/omnimemory/models/foundation/model_progress_summary.py
new file mode 100644
index 0000000..ba64c3f
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_progress_summary.py
@@ -0,0 +1,85 @@
+"""
+ONEX-compliant typed models for migration progress summaries.
+
+This module provides strongly typed replacements for Dict[str, Any] patterns
+in progress reporting, ensuring type safety and validation.
+"""
+
+from datetime import datetime
+from typing import List, Optional
+from pydantic import BaseModel, Field
+
+from ..enums.enum_migration_status import MigrationStatus
+from ..enums.enum_priority_level import PriorityLevel
+
+
+class ProgressSummaryResponse(BaseModel):
+    """Strongly typed progress summary response."""
+
+    migration_id: str = Field(
+        description="Unique identifier for the migration"
+    )
+
+    name: str = Field(
+        description="Human-readable name of the migration"
+    )
+
+    status: MigrationStatus = Field(
+        description="Current migration status"
+    )
+
+    priority: PriorityLevel = Field(
+        description="Migration priority level"
+    )
+
+    completion_percentage: float = Field(
+        description="Percentage of completion (0.0-100.0)"
+    )
+
+    success_rate: float = Field(
+        description="Success rate of processed items (0.0-1.0)"
+    )
+
+    elapsed_time: str = Field(
+        description="Time elapsed since migration started"
+    )
+
+    estimated_completion: Optional[datetime] = Field(
+        default=None,
+        description="Estimated completion time"
+    )
+
+    total_items: int = Field(
+        description="Total number of items to migrate"
+    )
+
+    processed_items: int = Field(
+        description="Number of items processed"
+    )
+
+    successful_items: int = Field(
+        description="Number of successfully processed items"
+    )
+
+    failed_items: int = Field(
+        description="Number of failed items"
+    )
+
+    current_batch_id: Optional[str] = Field(
+        default=None,
+        description="Current batch being processed"
+    )
+
+    active_workers: int = Field(
+        description="Number of active worker processes"
+    )
+
+    recent_errors: List[str] = Field(
+        default_factory=list,
+        description="Recent error messages"
+    )
+
+    performance_metrics: dict = Field(
+        default_factory=dict,
+        description="Performance metrics for the migration"
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_semver.py b/src/omnimemory/models/foundation/model_semver.py
new file mode 100644
index 0000000..f34cfa4
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_semver.py
@@ -0,0 +1,163 @@
+"""
+Semantic version model following ONEX standards.
+"""
+
+import re
+from typing import Self
+
+from pydantic import BaseModel, Field, field_validator
+
+
+class ModelSemVer(BaseModel):
+    """Semantic version model following ONEX standards."""
+
+    major: int = Field(
+        ge=0,
+        description="Major version number (breaking changes)",
+    )
+    minor: int = Field(
+        ge=0,
+        description="Minor version number (backward compatible features)",
+    )
+    patch: int = Field(
+        ge=0,
+        description="Patch version number (backward compatible fixes)",
+    )
+    pre_release: str | None = Field(
+        default=None,
+        description="Pre-release identifier (e.g., 'alpha.1', 'beta.2', 'rc.1')",
+    )
+    build_metadata: str | None = Field(
+        default=None,
+        description="Build metadata identifier",
+    )
+
+    @field_validator("pre_release")
+    @classmethod
+    def validate_pre_release(cls, v: str | None) -> str | None:
+        """Validate pre-release identifier format."""
+        if v is None:
+            return v
+        if not re.match(r"^[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*$", v):
+            raise ValueError("Invalid pre-release identifier format")
+        return v
+
+    @field_validator("build_metadata")
+    @classmethod
+    def validate_build_metadata(cls, v: str | None) -> str | None:
+        """Validate build metadata identifier format."""
+        if v is None:
+            return v
+        if not re.match(r"^[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*$", v):
+            raise ValueError("Invalid build metadata identifier format")
+        return v
+
+    def __str__(self) -> str:
+        """Return string representation of semantic version."""
+        version = f"{self.major}.{self.minor}.{self.patch}"
+        if self.pre_release:
+            version += f"-{self.pre_release}"
+        if self.build_metadata:
+            version += f"+{self.build_metadata}"
+        return version
+
+    def __lt__(self, other: Self) -> bool:
+        """Compare versions for less than."""
+        if not isinstance(other, ModelSemVer):
+            return NotImplemented
+        
+        # Compare major.minor.patch
+        self_core = (self.major, self.minor, self.patch)
+        other_core = (other.major, other.minor, other.patch)
+        
+        if self_core != other_core:
+            return self_core < other_core
+        
+        # Handle pre-release comparison
+        if self.pre_release is None and other.pre_release is None:
+            return False
+        if self.pre_release is None:
+            return False  # 1.0.0 > 1.0.0-alpha
+        if other.pre_release is None:
+            return True   # 1.0.0-alpha < 1.0.0
+        
+        return self.pre_release < other.pre_release
+
+    def __eq__(self, other: object) -> bool:
+        """Compare versions for equality."""
+        if not isinstance(other, ModelSemVer):
+            return NotImplemented
+        return (
+            self.major == other.major
+            and self.minor == other.minor
+            and self.patch == other.patch
+            and self.pre_release == other.pre_release
+        )
+
+    def __le__(self, other: Self) -> bool:
+        """Compare versions for less than or equal."""
+        return self == other or self < other
+
+    def __gt__(self, other: Self) -> bool:
+        """Compare versions for greater than."""
+        return not self <= other
+
+    def __ge__(self, other: Self) -> bool:
+        """Compare versions for greater than or equal."""
+        return not self < other
+
+    @classmethod
+    def from_string(cls, version_string: str) -> Self:
+        """Create ModelSemVer from string representation."""
+        # Regular expression to match semantic version
+        pattern = (
+            r"^(?P<major>0|[1-9]\d*)\."
+            r"(?P<minor>0|[1-9]\d*)\."
+            r"(?P<patch>0|[1-9]\d*)"
+            r"(?:-(?P<prerelease>[0-9A-Za-z-]+(?:\.[0-9A-Za-z-]+)*))?"
+            r"(?:\+(?P<buildmetadata>[0-9A-Za-z-]+(?:\.[0-9A-Za-z-]+)*))?$"
+        )
+        
+        match = re.match(pattern, version_string.strip())
+        if not match:
+            raise ValueError(f"Invalid semantic version format: {version_string}")
+        
+        return cls(
+            major=int(match.group("major")),
+            minor=int(match.group("minor")),
+            patch=int(match.group("patch")),
+            pre_release=match.group("prerelease"),
+            build_metadata=match.group("buildmetadata"),
+        )
+
+    def increment_major(self) -> Self:
+        """Create new version with incremented major version."""
+        return ModelSemVer(
+            major=self.major + 1,
+            minor=0,
+            patch=0,
+        )
+
+    def increment_minor(self) -> Self:
+        """Create new version with incremented minor version."""
+        return ModelSemVer(
+            major=self.major,
+            minor=self.minor + 1,
+            patch=0,
+        )
+
+    def increment_patch(self) -> Self:
+        """Create new version with incremented patch version."""
+        return ModelSemVer(
+            major=self.major,
+            minor=self.minor,
+            patch=self.patch + 1,
+        )
+
+    def is_stable(self) -> bool:
+        """Check if this is a stable release version."""
+        return self.pre_release is None
+
+    def is_compatible_with(self, other: Self) -> bool:
+        """Check if this version is compatible with another (same major version)."""
+        return self.major == other.major and self >= other
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_success_metrics.py b/src/omnimemory/models/foundation/model_success_metrics.py
new file mode 100644
index 0000000..c83e6a5
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_success_metrics.py
@@ -0,0 +1,150 @@
+"""
+Success metrics models following ONEX standards.
+"""
+
+from datetime import datetime
+
+from pydantic import BaseModel, Field, field_validator
+
+
+class ModelSuccessRate(BaseModel):
+    """Success rate metric following ONEX standards."""
+
+    rate: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Success rate as a decimal between 0.0 and 1.0",
+    )
+    total_operations: int = Field(
+        ge=0,
+        description="Total number of operations measured",
+    )
+    successful_operations: int = Field(
+        ge=0,
+        description="Number of successful operations",
+    )
+    calculation_window_start: datetime = Field(
+        description="Start time of the calculation window",
+    )
+    calculation_window_end: datetime = Field(
+        description="End time of the calculation window",
+    )
+    measurement_type: str = Field(
+        description="Type of operation measured (e.g., 'memory_storage', 'retrieval')",
+    )
+
+    @field_validator("successful_operations")
+    @classmethod
+    def validate_successful_operations(cls, v: int, info) -> int:
+        """Validate successful operations doesn't exceed total."""
+        if hasattr(info, "data") and "total_operations" in info.data:
+            total = info.data["total_operations"]
+            if v > total:
+                raise ValueError("Successful operations cannot exceed total operations")
+        return v
+
+    @property
+    def failure_rate(self) -> float:
+        """Calculate failure rate."""
+        return 1.0 - self.rate
+
+    @property
+    def failed_operations(self) -> int:
+        """Calculate number of failed operations."""
+        return self.total_operations - self.successful_operations
+
+    def to_percentage(self) -> float:
+        """Convert rate to percentage."""
+        return self.rate * 100.0
+
+
+class ModelConfidenceScore(BaseModel):
+    """Confidence score metric following ONEX standards."""
+
+    score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Confidence score as a decimal between 0.0 and 1.0",
+    )
+    measurement_basis: str = Field(
+        description="Basis for confidence measurement (e.g., 'data_quality', 'algorithm_certainty')",
+    )
+    contributing_factors: list[str] = Field(
+        default_factory=list,
+        description="Factors that contributed to this confidence score",
+    )
+    reliability_indicators: dict[str, float] = Field(
+        default_factory=dict,
+        description="Individual reliability indicators and their values",
+    )
+    sample_size: int | None = Field(
+        default=None,
+        ge=0,
+        description="Sample size used for confidence calculation",
+    )
+    calculation_method: str = Field(
+        description="Method used to calculate confidence (e.g., 'statistical', 'heuristic', 'ml_based')",
+    )
+    measured_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the confidence score was calculated",
+    )
+
+    @property
+    def confidence_level(self) -> str:
+        """Get human-readable confidence level."""
+        if self.score >= 0.9:
+            return "Very High"
+        elif self.score >= 0.75:
+            return "High"
+        elif self.score >= 0.5:
+            return "Medium"
+        elif self.score >= 0.25:
+            return "Low"
+        else:
+            return "Very Low"
+
+    def to_percentage(self) -> float:
+        """Convert score to percentage."""
+        return self.score * 100.0
+
+    def is_reliable(self, threshold: float = 0.7) -> bool:
+        """Check if confidence score meets reliability threshold."""
+        return self.score >= threshold
+
+
+class ModelQualityMetrics(BaseModel):
+    """Combined quality metrics following ONEX standards."""
+
+    success_rate: ModelSuccessRate = Field(
+        description="Success rate metrics",
+    )
+    confidence_score: ModelConfidenceScore = Field(
+        description="Confidence score metrics",
+    )
+    reliability_index: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Combined reliability index based on success rate and confidence",
+    )
+    quality_grade: str = Field(
+        description="Overall quality grade (A+, A, B+, B, C+, C, D, F)",
+    )
+    improvement_suggestions: list[str] = Field(
+        default_factory=list,
+        description="Suggestions for improving quality metrics",
+    )
+
+    @field_validator("quality_grade")
+    @classmethod
+    def validate_quality_grade(cls, v: str) -> str:
+        """Validate quality grade format."""
+        valid_grades = {"A+", "A", "B+", "B", "C+", "C", "D", "F"}
+        if v not in valid_grades:
+            raise ValueError(f"Quality grade must be one of {valid_grades}")
+        return v
+
+    @property
+    def is_high_quality(self) -> bool:
+        """Check if metrics indicate high quality."""
+        return self.quality_grade in {"A+", "A", "B+"} and self.reliability_index >= 0.8
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_system_health.py b/src/omnimemory/models/foundation/model_system_health.py
new file mode 100644
index 0000000..e5996a4
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_system_health.py
@@ -0,0 +1,177 @@
+"""
+System health model following ONEX standards.
+"""
+
+from datetime import datetime
+
+from pydantic import BaseModel, Field
+
+from omnibase_core.enums.node import EnumHealthStatus
+
+
+class ModelSystemHealth(BaseModel):
+    """System health information following ONEX standards."""
+
+    # System identification
+    system_id: str = Field(
+        description="Unique identifier for the system",
+    )
+    system_name: str = Field(
+        description="Human-readable name for the system",
+    )
+    system_version: str = Field(
+        description="Version of the system",
+    )
+
+    # Overall health status
+    overall_status: EnumHealthStatus = Field(
+        description="Overall system health status",
+    )
+    is_healthy: bool = Field(
+        description="Whether the system is considered healthy",
+    )
+    health_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Overall health score (0.0 = critical, 1.0 = perfect)",
+    )
+
+    # System uptime
+    uptime_seconds: int = Field(
+        description="System uptime in seconds",
+    )
+    last_restart_at: datetime | None = Field(
+        default=None,
+        description="When the system was last restarted",
+    )
+
+    # Resource utilization
+    cpu_usage_percent: float = Field(
+        ge=0.0,
+        le=100.0,
+        description="Current CPU usage percentage",
+    )
+    memory_usage_mb: float = Field(
+        description="Current memory usage in megabytes",
+    )
+    memory_usage_percent: float = Field(
+        ge=0.0,
+        le=100.0,
+        description="Memory usage as percentage of total",
+    )
+    disk_usage_percent: float = Field(
+        ge=0.0,
+        le=100.0,
+        description="Disk usage percentage",
+    )
+
+    # Performance metrics
+    average_response_time_ms: float = Field(
+        description="Average response time in milliseconds",
+    )
+    requests_per_second: float = Field(
+        description="Current requests per second",
+    )
+    error_rate: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Error rate as a percentage",
+    )
+
+    # Service health
+    total_services: int = Field(
+        description="Total number of services",
+    )
+    healthy_services: int = Field(
+        description="Number of healthy services",
+    )
+    degraded_services: int = Field(
+        description="Number of degraded services",
+    )
+    unhealthy_services: int = Field(
+        description="Number of unhealthy services",
+    )
+
+    # Database health
+    database_connections_active: int = Field(
+        description="Number of active database connections",
+    )
+    database_connections_max: int = Field(
+        description="Maximum database connections allowed",
+    )
+    database_response_time_ms: float = Field(
+        description="Average database response time in milliseconds",
+    )
+
+    # Cache health
+    cache_hit_rate: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Cache hit rate percentage",
+    )
+    cache_memory_usage_mb: float = Field(
+        description="Cache memory usage in megabytes",
+    )
+
+    # Network health
+    network_latency_ms: float = Field(
+        description="Average network latency in milliseconds",
+    )
+    network_throughput_mbps: float = Field(
+        description="Network throughput in megabits per second",
+    )
+
+    # Alerts and issues
+    active_alerts: list[str] = Field(
+        default_factory=list,
+        description="List of active alerts",
+    )
+    critical_issues: list[str] = Field(
+        default_factory=list,
+        description="List of critical issues",
+    )
+    warnings: list[str] = Field(
+        default_factory=list,
+        description="List of current warnings",
+    )
+
+    # Trends
+    health_trend: str = Field(
+        default="stable",
+        description="Health trend (improving, stable, degrading)",
+    )
+    performance_trend: str = Field(
+        default="stable",
+        description="Performance trend (improving, stable, degrading)",
+    )
+
+    # Check information
+    last_health_check: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the health check was performed",
+    )
+    health_check_duration_ms: float = Field(
+        description="Duration of the health check in milliseconds",
+    )
+    next_health_check: datetime | None = Field(
+        default=None,
+        description="When the next health check is scheduled",
+    )
+
+    # System metadata
+    environment: str = Field(
+        description="Environment (development, staging, production)",
+    )
+    region: str = Field(
+        description="Deployment region",
+    )
+    cluster_id: str | None = Field(
+        default=None,
+        description="Cluster identifier if applicable",
+    )
+
+    # Custom health metrics
+    custom_metrics: dict[str, float] = Field(
+        default_factory=dict,
+        description="Custom health metrics specific to the system",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_tags.py b/src/omnimemory/models/foundation/model_tags.py
new file mode 100644
index 0000000..38d175e
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_tags.py
@@ -0,0 +1,127 @@
+"""
+Tags model following ONEX standards.
+"""
+
+from datetime import datetime
+from typing import Optional, Set
+from uuid import UUID
+
+from pydantic import BaseModel, Field, field_validator
+
+
+class ModelTag(BaseModel):
+    """Individual tag model with metadata."""
+    
+    name: str = Field(
+        description="Tag name",
+        min_length=1,
+        max_length=100,
+    )
+    category: Optional[str] = Field(
+        default=None,
+        description="Optional tag category for organization",
+        max_length=50,
+    )
+    created_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the tag was created",
+    )
+    created_by: Optional[UUID] = Field(
+        default=None,
+        description="User who created the tag",
+    )
+    weight: float = Field(
+        default=1.0,
+        ge=0.0,
+        le=10.0,
+        description="Tag importance weight",
+    )
+    
+    @field_validator('name')
+    @classmethod
+    def validate_tag_name(cls, v):
+        """Validate tag name format."""
+        # Remove whitespace and convert to lowercase
+        v = v.strip().lower()
+        
+        # Check for invalid characters
+        invalid_chars = set('!@#$%^&*()+={}[]|\\:";\'<>?,/`~')
+        if any(char in v for char in invalid_chars):
+            raise ValueError(f"Tag name contains invalid characters: {v}")
+        
+        # Replace spaces with underscores
+        v = v.replace(' ', '_').replace('-', '_')
+        
+        return v
+
+
+class ModelTagCollection(BaseModel):
+    """Collection of tags with validation and management."""
+    
+    tags: list[ModelTag] = Field(
+        default_factory=list,
+        description="Collection of tags",
+        max_length=100,  # Maximum 100 tags
+    )
+    auto_generated: bool = Field(
+        default=False,
+        description="Whether tags were auto-generated",
+    )
+    last_updated: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the tag collection was last updated",
+    )
+    
+    @field_validator('tags')
+    @classmethod
+    def validate_unique_tags(cls, v):
+        """Ensure tag names are unique."""
+        tag_names = [tag.name for tag in v]
+        if len(tag_names) != len(set(tag_names)):
+            raise ValueError("Duplicate tag names are not allowed")
+        return v
+    
+    def add_tag(self, name: str, category: Optional[str] = None, weight: float = 1.0, created_by: Optional[UUID] = None) -> None:
+        """Add a new tag to the collection."""
+        # Check if tag already exists
+        if any(tag.name == name.strip().lower().replace(' ', '_').replace('-', '_') for tag in self.tags):
+            return  # Tag already exists, skip
+            
+        new_tag = ModelTag(
+            name=name,
+            category=category,
+            weight=weight,
+            created_by=created_by,
+        )
+        self.tags.append(new_tag)
+        self.last_updated = datetime.utcnow()
+    
+    def remove_tag(self, name: str) -> bool:
+        """Remove a tag by name."""
+        normalized_name = name.strip().lower().replace(' ', '_').replace('-', '_')
+        for i, tag in enumerate(self.tags):
+            if tag.name == normalized_name:
+                self.tags.pop(i)
+                self.last_updated = datetime.utcnow()
+                return True
+        return False
+    
+    def get_tag_names(self) -> list[str]:
+        """Get list of tag names."""
+        return [tag.name for tag in self.tags]
+    
+    def get_tags_by_category(self, category: str) -> list[ModelTag]:
+        """Get tags filtered by category."""
+        return [tag for tag in self.tags if tag.category == category]
+    
+    def get_weighted_tags(self) -> list[tuple[str, float]]:
+        """Get tags with their weights."""
+        return [(tag.name, tag.weight) for tag in self.tags]
+    
+    @classmethod
+    def from_string_list(cls, tag_names: list[str], created_by: Optional[UUID] = None) -> "ModelTagCollection":
+        """Create tag collection from legacy string list."""
+        collection = cls()
+        for name in tag_names:
+            collection.add_tag(name, created_by=created_by)
+        return collection
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_trust_score.py b/src/omnimemory/models/foundation/model_trust_score.py
new file mode 100644
index 0000000..391ff15
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_trust_score.py
@@ -0,0 +1,218 @@
+"""
+Trust score model with time decay following ONEX standards.
+"""
+
+import math
+from datetime import datetime, timedelta
+from functools import lru_cache
+from typing import Optional
+from uuid import UUID
+
+from pydantic import BaseModel, Field, field_validator
+
+from omnimemory.enums import EnumTrustLevel, EnumDecayFunction
+
+
+class ModelTrustScore(BaseModel):
+    """Trust score with time-based decay and validation."""
+    
+    base_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Base trust score without time decay",
+    )
+    current_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Current trust score with time decay applied",
+    )
+    trust_level: EnumTrustLevel = Field(
+        description="Categorical trust level",
+    )
+    
+    # Time decay configuration
+    decay_function: EnumDecayFunction = Field(
+        default=EnumDecayFunction.EXPONENTIAL,
+        description="Type of time decay function to apply",
+    )
+    decay_rate: float = Field(
+        default=0.01,
+        ge=0.0,
+        le=1.0,
+        description="Rate of trust decay (0=no decay, 1=fast decay)",
+    )
+    half_life_days: int = Field(
+        default=30,
+        ge=1,
+        le=3650,
+        description="Days for trust score to decay to half value",
+    )
+    
+    # Temporal information
+    initial_timestamp: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the trust score was initially established",
+    )
+    last_updated: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the trust score was last updated",
+    )
+    last_verified: Optional[datetime] = Field(
+        default=None,
+        description="When the trust was last externally verified",
+    )
+    
+    # Metadata
+    source_node_id: Optional[UUID] = Field(
+        default=None,
+        description="Node that established this trust score",
+    )
+    verification_count: int = Field(
+        default=0,
+        ge=0,
+        description="Number of times this trust has been verified",
+    )
+    violation_count: int = Field(
+        default=0,
+        ge=0,
+        description="Number of trust violations recorded",
+    )
+
+    # Performance optimization caching
+    _cached_score: Optional[float] = Field(
+        default=None,
+        exclude=True,
+        description="Cached current score to avoid expensive recalculation",
+    )
+    _cache_timestamp: Optional[datetime] = Field(
+        default=None,
+        exclude=True,
+        description="Timestamp when the score was cached",
+    )
+    _cache_ttl_seconds: int = Field(
+        default=300,  # 5 minutes cache TTL
+        exclude=True,
+        description="Cache time-to-live in seconds",
+    )
+    
+    @field_validator('trust_level')
+    @classmethod
+    def validate_trust_level_matches_score(cls, v, info):
+        """Ensure trust level matches base score."""
+        if 'current_score' in info.data:
+            score = info.data['current_score']
+            expected_level = cls._score_to_level(score)
+            if v != expected_level:
+                raise ValueError(f"Trust level {v} doesn't match score {score}, expected {expected_level}")
+        return v
+    
+    @staticmethod
+    def _score_to_level(score: float) -> EnumTrustLevel:
+        """Convert numeric score to trust level."""
+        if score >= 0.9:
+            return EnumTrustLevel.VERIFIED
+        elif score >= 0.7:
+            return EnumTrustLevel.HIGH
+        elif score >= 0.5:
+            return EnumTrustLevel.MEDIUM
+        elif score >= 0.2:
+            return EnumTrustLevel.LOW
+        else:
+            return EnumTrustLevel.UNTRUSTED
+    
+    def calculate_current_score(self, as_of: Optional[datetime] = None, force_recalculate: bool = False) -> float:
+        """Calculate current trust score with time decay and caching for performance."""
+        if as_of is None:
+            as_of = datetime.utcnow()
+
+        # Check cache validity if not forcing recalculation
+        if not force_recalculate and self._is_cache_valid(as_of):
+            return self._cached_score
+
+        if self.decay_function == EnumDecayFunction.NONE:
+            score = self.base_score
+            self._update_cache(score, as_of)
+            return score
+
+        # Calculate time elapsed
+        time_elapsed = as_of - self.last_updated
+        days_elapsed = time_elapsed.total_seconds() / 86400  # Convert to days
+
+        if days_elapsed <= 0:
+            score = self.base_score
+            self._update_cache(score, as_of)
+            return score
+
+        # Apply decay function
+        if self.decay_function == EnumDecayFunction.LINEAR:
+            decay_factor = max(0, 1 - (days_elapsed * self.decay_rate))
+        elif self.decay_function == EnumDecayFunction.EXPONENTIAL:
+            decay_factor = math.exp(-days_elapsed / self.half_life_days * math.log(2))
+        elif self.decay_function == EnumDecayFunction.LOGARITHMIC:
+            decay_factor = max(0, 1 - (math.log(1 + days_elapsed) * self.decay_rate))
+        else:
+            decay_factor = 1.0
+
+        decayed_score = self.base_score * decay_factor
+        score = max(0.0, min(1.0, decayed_score))
+
+        # Cache the calculated score
+        self._update_cache(score, as_of)
+        return score
+
+    def _is_cache_valid(self, as_of: datetime) -> bool:
+        """Check if cached score is still valid."""
+        if self._cached_score is None or self._cache_timestamp is None:
+            return False
+
+        cache_age = (as_of - self._cache_timestamp).total_seconds()
+        return cache_age < self._cache_ttl_seconds
+
+    def _update_cache(self, score: float, timestamp: datetime) -> None:
+        """Update cached score and timestamp."""
+        self._cached_score = score
+        self._cache_timestamp = timestamp
+
+    def invalidate_cache(self) -> None:
+        """Manually invalidate the score cache."""
+        self._cached_score = None
+        self._cache_timestamp = None
+    
+    def update_score(self, new_base_score: float, verified: bool = False) -> None:
+        """Update the trust score and invalidate cache."""
+        # Invalidate cache since base parameters changed
+        self.invalidate_cache()
+
+        self.base_score = new_base_score
+        self.current_score = self.calculate_current_score()
+        self.trust_level = self._score_to_level(self.current_score)
+        self.last_updated = datetime.utcnow()
+        
+        if verified:
+            self.last_verified = datetime.utcnow()
+            self.verification_count += 1
+    
+    def record_violation(self, penalty: float = 0.1) -> None:
+        """Record a trust violation with penalty."""
+        self.violation_count += 1
+        penalty_factor = min(penalty * self.violation_count, 0.5)  # Max 50% penalty
+        self.base_score = max(0.0, self.base_score - penalty_factor)
+        self.current_score = self.calculate_current_score()
+        self.trust_level = self._score_to_level(self.current_score)
+        self.last_updated = datetime.utcnow()
+    
+    def refresh_current_score(self) -> None:
+        """Refresh the current score based on time decay."""
+        self.current_score = self.calculate_current_score()
+        self.trust_level = self._score_to_level(self.current_score)
+    
+    @classmethod
+    def create_from_float(cls, score: float, source_node_id: Optional[UUID] = None) -> "ModelTrustScore":
+        """Create trust score model from legacy float value."""
+        trust_level = cls._score_to_level(score)
+        return cls(
+            base_score=score,
+            current_score=score,
+            trust_level=trust_level,
+            source_node_id=source_node_id,
+        )
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_typed_collections.py b/src/omnimemory/models/foundation/model_typed_collections.py
new file mode 100644
index 0000000..66a7a46
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_typed_collections.py
@@ -0,0 +1,495 @@
+"""
+Typed Collections for ONEX Foundation Architecture
+
+This module provides strongly typed Pydantic models to replace generic types
+like Dict[str, Any], List[str], and List[Dict[str, Any]] throughout the codebase.
+
+All models follow ONEX standards with:
+- Strong typing with zero Any types
+- Comprehensive Field descriptions
+- Validation and serialization support
+- Monadic composition patterns
+"""
+
+from __future__ import annotations
+
+from typing import Any, List, Optional, Union
+from uuid import UUID
+
+from pydantic import BaseModel, ConfigDict, Field, field_validator
+
+
+# === STRING COLLECTIONS ===
+
+
+class ModelStringList(BaseModel):
+    """Strongly typed list of strings following ONEX standards."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    values: List[str] = Field(
+        default_factory=list,
+        description="List of string values with validation and deduplication"
+    )
+
+    @field_validator('values')
+    @classmethod
+    def validate_strings(cls, v):
+        """Validate and deduplicate string values."""
+        if not isinstance(v, list):
+            raise ValueError("values must be a list")
+
+        # Remove empty strings and duplicates while preserving order
+        # Use O(1) set operations for efficient deduplication
+        seen = set()
+        result = []
+        for item in v:
+            if item:
+                stripped_item = item.strip()
+                if stripped_item and stripped_item not in seen:
+                    seen.add(stripped_item)
+                    result.append(stripped_item)
+
+        return result
+
+
+class ModelOptionalStringList(BaseModel):
+    """Optional strongly typed list of strings."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    values: Optional[List[str]] = Field(
+        default=None,
+        description="Optional list of string values, None if not set"
+    )
+
+    @field_validator('values')
+    @classmethod
+    def validate_optional_strings(cls, v):
+        """Validate optional string values."""
+        if v is None:
+            return None
+
+        if not isinstance(v, list):
+            raise ValueError("values must be a list or None")
+
+        # Remove empty strings and duplicates while preserving order
+        # Use O(1) set operations for efficient deduplication
+        seen = set()
+        result = []
+        for item in v:
+            if item:
+                stripped_item = item.strip()
+                if stripped_item and stripped_item not in seen:
+                    seen.add(stripped_item)
+                    result.append(stripped_item)
+
+        return result if result else None
+
+
+# === METADATA COLLECTIONS ===
+
+
+class ModelKeyValuePair(BaseModel):
+    """Strongly typed key-value pair for metadata."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    key: str = Field(description="Metadata key identifier")
+    value: str = Field(description="Metadata value content")
+
+    @field_validator('key')
+    @classmethod
+    def validate_key(cls, v):
+        """Validate metadata key format."""
+        if not v or not v.strip():
+            raise ValueError("key cannot be empty")
+        return v.strip()
+
+
+class ModelMetadata(BaseModel):
+    """Strongly typed metadata collection replacing Dict[str, Any]."""
+
+    model_config = ConfigDict(
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    pairs: List[ModelKeyValuePair] = Field(
+        default_factory=list,
+        description="List of key-value pairs for metadata storage"
+    )
+
+    def get_value(self, key: str) -> Optional[str]:
+        """Get metadata value by key."""
+        for pair in self.pairs:
+            if pair.key == key:
+                return pair.value
+        return None
+
+    def set_value(self, key: str, value: str) -> None:
+        """Set metadata value by key."""
+        # Update existing or add new
+        for pair in self.pairs:
+            if pair.key == key:
+                pair.value = value
+                return
+
+        self.pairs.append(ModelKeyValuePair(key=key, value=value))
+
+    def to_dict(self) -> dict[str, str]:
+        """Convert to dictionary format for backward compatibility."""
+        return {pair.key: pair.value for pair in self.pairs}
+
+    @classmethod
+    def from_dict(cls, data: dict[str, Any]) -> ModelMetadata:
+        """Create from dictionary, converting values to strings."""
+        pairs = [
+            ModelKeyValuePair(key=str(k), value=str(v))
+            for k, v in data.items()
+            if k and v is not None
+        ]
+        return cls(pairs=pairs)
+
+
+# === STRUCTURED DATA COLLECTIONS ===
+
+
+class ModelStructuredField(BaseModel):
+    """Strongly typed field for structured data."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    name: str = Field(description="Field name identifier")
+    value: str = Field(description="Field value content")
+    field_type: str = Field(
+        default="string",
+        description="Field type indicator (string, number, boolean, etc.)"
+    )
+
+    @field_validator('name')
+    @classmethod
+    def validate_name(cls, v):
+        """Validate field name format."""
+        if not v or not v.strip():
+            raise ValueError("name cannot be empty")
+        return v.strip()
+
+
+class ModelStructuredData(BaseModel):
+    """Strongly typed structured data replacing List[Dict[str, Any]]."""
+
+    model_config = ConfigDict(
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    fields: List[ModelStructuredField] = Field(
+        default_factory=list,
+        description="List of structured fields with type information"
+    )
+    schema_version: str = Field(
+        default="1.0",
+        description="Schema version for compatibility tracking"
+    )
+
+    def get_field_value(self, name: str) -> Optional[str]:
+        """Get field value by name."""
+        for field in self.fields:
+            if field.name == name:
+                return field.value
+        return None
+
+    def set_field_value(self, name: str, value: str, field_type: str = "string") -> None:
+        """Set field value by name."""
+        # Update existing or add new
+        for field in self.fields:
+            if field.name == name:
+                field.value = value
+                field.field_type = field_type
+                return
+
+        self.fields.append(ModelStructuredField(
+            name=name,
+            value=value,
+            field_type=field_type
+        ))
+
+
+# === CONFIGURATION COLLECTIONS ===
+
+
+class ModelConfigurationOption(BaseModel):
+    """Strongly typed configuration option."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    key: str = Field(description="Configuration option key")
+    value: str = Field(description="Configuration option value")
+    description: Optional[str] = Field(
+        default=None,
+        description="Option description for documentation"
+    )
+    is_sensitive: bool = Field(
+        default=False,
+        description="Whether this option contains sensitive data"
+    )
+
+    @field_validator('key')
+    @classmethod
+    def validate_key(cls, v):
+        """Validate configuration key format."""
+        if not v or not v.strip():
+            raise ValueError("key cannot be empty")
+        return v.strip()
+
+
+class ModelConfiguration(BaseModel):
+    """Strongly typed configuration replacing Dict[str, Any]."""
+
+    model_config = ConfigDict(
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    options: List[ModelConfigurationOption] = Field(
+        default_factory=list,
+        description="List of configuration options with metadata"
+    )
+
+    def get_option(self, key: str) -> Optional[str]:
+        """Get configuration option value by key."""
+        for option in self.options:
+            if option.key == key:
+                return option.value
+        return None
+
+    def set_option(
+        self,
+        key: str,
+        value: str,
+        description: Optional[str] = None,
+        is_sensitive: bool = False
+    ) -> None:
+        """Set configuration option with metadata."""
+        # Update existing or add new
+        for option in self.options:
+            if option.key == key:
+                option.value = value
+                if description is not None:
+                    option.description = description
+                option.is_sensitive = is_sensitive
+                return
+
+        self.options.append(ModelConfigurationOption(
+            key=key,
+            value=value,
+            description=description,
+            is_sensitive=is_sensitive
+        ))
+
+
+# === EVENT AND LOG COLLECTIONS ===
+
+
+class ModelEventData(BaseModel):
+    """Strongly typed event data for system events."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    event_type: str = Field(description="Type of event (creation, update, deletion, etc.)")
+    timestamp: str = Field(description="ISO 8601 timestamp of the event")
+    source: str = Field(description="Source system or component generating the event")
+    severity: str = Field(
+        default="info",
+        description="Event severity level (debug, info, warning, error, critical)"
+    )
+    message: str = Field(description="Human-readable event message")
+    correlation_id: Optional[str] = Field(
+        default=None,
+        description="Correlation ID for tracking related events"
+    )
+
+    @field_validator('event_type')
+    @classmethod
+    def validate_event_type(cls, v):
+        """Validate event type format."""
+        if not v or not v.strip():
+            raise ValueError("event_type cannot be empty")
+        return v.strip().lower()
+
+    @field_validator('severity')
+    @classmethod
+    def validate_severity(cls, v):
+        """Validate severity level."""
+        valid_levels = {"debug", "info", "warning", "error", "critical"}
+        if v.lower() not in valid_levels:
+            raise ValueError(f"severity must be one of: {valid_levels}")
+        return v.lower()
+
+
+class ModelEventCollection(BaseModel):
+    """Strongly typed event collection replacing List[Dict[str, Any]]."""
+
+    model_config = ConfigDict(
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    events: List[ModelEventData] = Field(
+        default_factory=list,
+        description="List of system events with structured data"
+    )
+
+    def add_event(
+        self,
+        event_type: str,
+        timestamp: str,
+        source: str,
+        message: str,
+        severity: str = "info",
+        correlation_id: Optional[str] = None
+    ) -> None:
+        """Add a new event to the collection."""
+        event = ModelEventData(
+            event_type=event_type,
+            timestamp=timestamp,
+            source=source,
+            message=message,
+            severity=severity,
+            correlation_id=correlation_id
+        )
+        self.events.append(event)
+
+    def get_events_by_type(self, event_type: str) -> List[ModelEventData]:
+        """Get all events of a specific type."""
+        return [event for event in self.events if event.event_type == event_type]
+
+    def get_events_by_severity(self, severity: str) -> List[ModelEventData]:
+        """Get all events of a specific severity."""
+        return [event for event in self.events if event.severity == severity.lower()]
+
+
+# === RESULT AND RESPONSE COLLECTIONS ===
+
+
+class ModelResultItem(BaseModel):
+    """Strongly typed result item for operation results."""
+
+    model_config = ConfigDict(
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    id: str = Field(description="Unique identifier for this result item")
+    status: str = Field(description="Status of this specific item (success, failure, pending)")
+    message: str = Field(description="Human-readable message about this item")
+    data: Optional[ModelStructuredData] = Field(
+        default=None,
+        description="Structured data associated with this item"
+    )
+
+    @field_validator('status')
+    @classmethod
+    def validate_status(cls, v):
+        """Validate status values."""
+        valid_statuses = {"success", "failure", "pending", "partial", "cancelled"}
+        if v.lower() not in valid_statuses:
+            raise ValueError(f"status must be one of: {valid_statuses}")
+        return v.lower()
+
+
+class ModelResultCollection(BaseModel):
+    """Strongly typed result collection replacing List[Dict[str, Any]]."""
+
+    model_config = ConfigDict(
+        validate_assignment=True,
+        extra="forbid"
+    )
+
+    results: List[ModelResultItem] = Field(
+        default_factory=list,
+        description="List of operation results with structured data"
+    )
+
+    def add_result(
+        self,
+        id: str,
+        status: str,
+        message: str,
+        data: Optional[ModelStructuredData] = None
+    ) -> None:
+        """Add a new result to the collection."""
+        result = ModelResultItem(
+            id=id,
+            status=status,
+            message=message,
+            data=data
+        )
+        self.results.append(result)
+
+    def get_successful_results(self) -> List[ModelResultItem]:
+        """Get all successful results."""
+        return [result for result in self.results if result.status == "success"]
+
+    def get_failed_results(self) -> List[ModelResultItem]:
+        """Get all failed results."""
+        return [result for result in self.results if result.status == "failure"]
+
+
+# === UTILITY FUNCTIONS ===
+
+
+def convert_dict_to_metadata(data: dict[str, Any]) -> ModelMetadata:
+    """Convert a dictionary to ModelMetadata."""
+    return ModelMetadata.from_dict(data)
+
+
+def convert_list_to_string_list(data: List[str]) -> ModelStringList:
+    """Convert a list of strings to ModelStringList."""
+    return ModelStringList(values=data)
+
+
+def convert_list_of_dicts_to_structured_data(data: List[dict[str, Any]]) -> ModelResultCollection:
+    """Convert a list of dictionaries to structured result collection."""
+    collection = ModelResultCollection()
+
+    for i, item in enumerate(data):
+        # Convert dict to structured data
+        structured_data = ModelStructuredData()
+        for key, value in item.items():
+            structured_data.set_field_value(key, str(value))
+
+        collection.add_result(
+            id=str(i),
+            status="success",
+            message=f"Converted item {i}",
+            data=structured_data
+        )
+
+    return collection
\ No newline at end of file
diff --git a/src/omnimemory/models/foundation/model_user.py b/src/omnimemory/models/foundation/model_user.py
new file mode 100644
index 0000000..f60327a
--- /dev/null
+++ b/src/omnimemory/models/foundation/model_user.py
@@ -0,0 +1,109 @@
+"""
+User model following ONEX foundation patterns.
+"""
+
+from datetime import datetime
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+
+class ModelUser(BaseModel):
+    """User model with comprehensive identity and authorization information."""
+
+    user_id: UUID = Field(
+        description="Unique user identifier",
+    )
+    username: str = Field(
+        description="Human-readable username",
+        min_length=1,
+        max_length=100,
+    )
+    email: str | None = Field(
+        default=None,
+        description="User email address for notifications and identity",
+    )
+    display_name: str | None = Field(
+        default=None,
+        description="Display name for user interface",
+    )
+
+    # Authorization and access
+    roles: list[str] = Field(
+        default_factory=list,
+        description="User roles for authorization",
+    )
+    permissions: list[str] = Field(
+        default_factory=list,
+        description="Specific permissions granted to user",
+    )
+
+    # Metadata
+    created_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the user was created",
+    )
+    last_active: datetime | None = Field(
+        default=None,
+        description="When the user was last active",
+    )
+    is_active: bool = Field(
+        default=True,
+        description="Whether the user account is active",
+    )
+
+    # Additional attributes
+    attributes: dict[str, str] = Field(
+        default_factory=dict,
+        description="Additional user attributes for customization",
+    )
+
+    def has_role(self, role: str) -> bool:
+        """Check if user has specific role."""
+        return role in self.roles
+
+    def has_permission(self, permission: str) -> bool:
+        """Check if user has specific permission."""
+        return permission in self.permissions
+
+    def add_role(self, role: str) -> None:
+        """Add role to user."""
+        if role not in self.roles:
+            self.roles.append(role)
+
+    def remove_role(self, role: str) -> None:
+        """Remove role from user."""
+        if role in self.roles:
+            self.roles.remove(role)
+
+    def update_last_active(self) -> None:
+        """Update last active timestamp to now."""
+        self.last_active = datetime.utcnow()
+
+    @classmethod
+    def create_system_user(cls) -> "ModelUser":
+        """Create a system user for automated operations."""
+        from uuid import uuid4
+
+        return cls(
+            user_id=uuid4(),
+            username="system",
+            display_name="System User",
+            roles=["system", "admin"],
+            permissions=["system.all"],
+            attributes={"type": "system", "automated": "true"}
+        )
+
+    @classmethod
+    def create_anonymous_user(cls) -> "ModelUser":
+        """Create an anonymous user for unauthenticated operations."""
+        from uuid import uuid4
+
+        return cls(
+            user_id=uuid4(),
+            username="anonymous",
+            display_name="Anonymous User",
+            roles=["anonymous"],
+            permissions=["read"],
+            attributes={"type": "anonymous", "temporary": "true"}
+        )
\ No newline at end of file
diff --git a/src/omnimemory/models/intelligence/__init__.py b/src/omnimemory/models/intelligence/__init__.py
new file mode 100644
index 0000000..80928e4
--- /dev/null
+++ b/src/omnimemory/models/intelligence/__init__.py
@@ -0,0 +1,18 @@
+"""
+Intelligence domain models for OmniMemory following ONEX standards.
+
+This module provides models for intelligence processing, analysis,
+pattern recognition, and semantic operations in the ONEX 4-node architecture.
+"""
+
+from ...enums.enum_intelligence_operation_type import EnumIntelligenceOperationType
+from .model_intelligence_analysis import ModelIntelligenceAnalysis
+from .model_pattern_recognition_result import ModelPatternRecognitionResult
+from .model_semantic_analysis_result import ModelSemanticAnalysisResult
+
+__all__ = [
+    "EnumIntelligenceOperationType",
+    "ModelIntelligenceAnalysis",
+    "ModelPatternRecognitionResult",
+    "ModelSemanticAnalysisResult",
+]
\ No newline at end of file
diff --git a/src/omnimemory/models/intelligence/model_intelligence_analysis.py b/src/omnimemory/models/intelligence/model_intelligence_analysis.py
new file mode 100644
index 0000000..696d46e
--- /dev/null
+++ b/src/omnimemory/models/intelligence/model_intelligence_analysis.py
@@ -0,0 +1,112 @@
+"""
+Intelligence analysis model following ONEX standards.
+"""
+
+from datetime import datetime
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+from ...enums.enum_intelligence_operation_type import EnumIntelligenceOperationType
+
+
+class ModelIntelligenceAnalysis(BaseModel):
+    """Intelligence analysis result following ONEX standards."""
+
+    # Analysis identification
+    analysis_id: UUID = Field(
+        description="Unique identifier for the analysis",
+    )
+    operation_type: EnumIntelligenceOperationType = Field(
+        description="Type of intelligence operation performed",
+    )
+
+    # Input information
+    input_content: str = Field(
+        description="Content that was analyzed",
+    )
+    input_type: str = Field(
+        description="Type of input content (text, document, etc.)",
+    )
+
+    # Analysis results
+    results: dict[str, str] = Field(
+        default_factory=dict,
+        description="Analysis results with string values for type safety",
+    )
+    insights: list[str] = Field(
+        default_factory=list,
+        description="Key insights derived from the analysis",
+    )
+    recommendations: list[str] = Field(
+        default_factory=list,
+        description="Recommendations based on the analysis",
+    )
+
+    # Confidence and quality metrics
+    confidence_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Confidence in the analysis results",
+    )
+    accuracy_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Estimated accuracy of the analysis",
+    )
+    completeness_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Completeness of the analysis",
+    )
+
+    # Processing information
+    processing_time_ms: int = Field(
+        description="Time taken to perform the analysis",
+    )
+    model_version: str = Field(
+        description="Version of the analysis model used",
+    )
+    algorithm_used: str = Field(
+        description="Algorithm or method used for analysis",
+    )
+
+    # Metadata and context
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Tags for categorizing the analysis",
+    )
+    context: dict[str, str] = Field(
+        default_factory=dict,
+        description="Additional context for the analysis",
+    )
+
+    # Temporal information
+    analyzed_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the analysis was performed",
+    )
+    expires_at: datetime | None = Field(
+        default=None,
+        description="When the analysis results expire",
+    )
+
+    # Quality assurance
+    validated: bool = Field(
+        default=False,
+        description="Whether the analysis has been validated",
+    )
+    validation_score: float | None = Field(
+        default=None,
+        description="Validation score if validated",
+    )
+
+    # Usage tracking
+    access_count: int = Field(
+        default=0,
+        description="Number of times this analysis has been accessed",
+    )
+    last_accessed_at: datetime | None = Field(
+        default=None,
+        description="When the analysis was last accessed",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/intelligence/model_pattern_recognition_result.py b/src/omnimemory/models/intelligence/model_pattern_recognition_result.py
new file mode 100644
index 0000000..8240045
--- /dev/null
+++ b/src/omnimemory/models/intelligence/model_pattern_recognition_result.py
@@ -0,0 +1,114 @@
+"""
+Pattern recognition result model following ONEX standards.
+"""
+
+from datetime import datetime
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+
+class ModelPatternRecognitionResult(BaseModel):
+    """Pattern recognition result following ONEX standards."""
+
+    # Result identification
+    result_id: UUID = Field(
+        description="Unique identifier for the pattern recognition result",
+    )
+    pattern_id: str = Field(
+        description="Identifier for the recognized pattern",
+    )
+
+    # Pattern information
+    pattern_name: str = Field(
+        description="Human-readable name for the pattern",
+    )
+    pattern_type: str = Field(
+        description="Type or category of the pattern",
+    )
+    pattern_description: str = Field(
+        description="Description of the recognized pattern",
+    )
+
+    # Recognition details
+    matched_content: str = Field(
+        description="Content that matched the pattern",
+    )
+    match_strength: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Strength of the pattern match",
+    )
+    match_confidence: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Confidence in the pattern recognition",
+    )
+
+    # Pattern characteristics
+    pattern_frequency: int = Field(
+        description="Frequency of this pattern in the dataset",
+    )
+    pattern_significance: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Statistical significance of the pattern",
+    )
+    pattern_uniqueness: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Uniqueness score of the pattern",
+    )
+
+    # Context information
+    context_window: str = Field(
+        description="Contextual window around the matched pattern",
+    )
+    related_patterns: list[str] = Field(
+        default_factory=list,
+        description="IDs of related patterns",
+    )
+
+    # Quality metrics
+    precision_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Precision of the pattern recognition",
+    )
+    recall_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Recall of the pattern recognition",
+    )
+    f1_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="F1 score of the pattern recognition",
+    )
+
+    # Processing information
+    algorithm_used: str = Field(
+        description="Algorithm used for pattern recognition",
+    )
+    model_version: str = Field(
+        description="Version of the pattern recognition model",
+    )
+    processing_time_ms: int = Field(
+        description="Time taken for pattern recognition",
+    )
+
+    # Temporal information
+    recognized_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the pattern was recognized",
+    )
+
+    # Metadata
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Tags for categorizing the pattern",
+    )
+    annotations: dict[str, str] = Field(
+        default_factory=dict,
+        description="Additional annotations for the pattern",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/intelligence/model_semantic_analysis_result.py b/src/omnimemory/models/intelligence/model_semantic_analysis_result.py
new file mode 100644
index 0000000..9374619
--- /dev/null
+++ b/src/omnimemory/models/intelligence/model_semantic_analysis_result.py
@@ -0,0 +1,128 @@
+"""
+Semantic analysis result model following ONEX standards.
+"""
+
+from datetime import datetime
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+
+class ModelSemanticAnalysisResult(BaseModel):
+    """Semantic analysis result following ONEX standards."""
+
+    # Result identification
+    result_id: UUID = Field(
+        description="Unique identifier for the semantic analysis result",
+    )
+    analysis_type: str = Field(
+        description="Type of semantic analysis performed",
+    )
+
+    # Input information
+    analyzed_content: str = Field(
+        description="Content that was semantically analyzed",
+    )
+    content_language: str = Field(
+        default="en",
+        description="Language of the analyzed content",
+    )
+
+    # Semantic features
+    semantic_vector: list[float] = Field(
+        default_factory=list,
+        description="Semantic vector representation of the content",
+    )
+    key_concepts: list[str] = Field(
+        default_factory=list,
+        description="Key concepts identified in the content",
+    )
+    entities: list[str] = Field(
+        default_factory=list,
+        description="Named entities found in the content",
+    )
+    topics: list[str] = Field(
+        default_factory=list,
+        description="Topics associated with the content",
+    )
+
+    # Semantic relationships
+    concept_relationships: dict[str, str] = Field(
+        default_factory=dict,
+        description="Relationships between concepts",
+    )
+    similarity_scores: dict[str, float] = Field(
+        default_factory=dict,
+        description="Similarity scores to reference concepts",
+    )
+
+    # Sentiment and emotion
+    sentiment_score: float = Field(
+        ge=-1.0,
+        le=1.0,
+        description="Sentiment score (-1 negative, +1 positive)",
+    )
+    emotion_scores: dict[str, float] = Field(
+        default_factory=dict,
+        description="Emotion scores for different emotions",
+    )
+
+    # Complexity and readability
+    complexity_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Complexity score of the content",
+    )
+    readability_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Readability score of the content",
+    )
+
+    # Quality metrics
+    coherence_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Coherence score of the content",
+    )
+    relevance_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Relevance score to the domain",
+    )
+    confidence_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Confidence in the semantic analysis",
+    )
+
+    # Processing information
+    model_name: str = Field(
+        description="Name of the semantic model used",
+    )
+    model_version: str = Field(
+        description="Version of the semantic model",
+    )
+    processing_time_ms: int = Field(
+        description="Time taken for semantic analysis",
+    )
+
+    # Temporal information
+    analyzed_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the semantic analysis was performed",
+    )
+
+    # Context and metadata
+    domain_context: str | None = Field(
+        default=None,
+        description="Domain context for the analysis",
+    )
+    analysis_parameters: dict[str, str] = Field(
+        default_factory=dict,
+        description="Parameters used for the analysis",
+    )
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Tags for categorizing the analysis",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/memory/__init__.py b/src/omnimemory/models/memory/__init__.py
new file mode 100644
index 0000000..62a9eeb
--- /dev/null
+++ b/src/omnimemory/models/memory/__init__.py
@@ -0,0 +1,20 @@
+"""
+Memory domain models for OmniMemory following ONEX standards.
+
+This module provides models for memory storage, retrieval, persistence,
+and management operations in the ONEX 4-node architecture.
+"""
+
+from ...enums.enum_memory_storage_type import EnumMemoryStorageType
+from .model_memory_item import ModelMemoryItem
+from .model_memory_query import ModelMemoryQuery
+from .model_memory_search_result import ModelMemorySearchResult
+from .model_memory_storage_config import ModelMemoryStorageConfig
+
+__all__ = [
+    "EnumMemoryStorageType",
+    "ModelMemoryItem",
+    "ModelMemoryQuery",
+    "ModelMemorySearchResult",
+    "ModelMemoryStorageConfig",
+]
\ No newline at end of file
diff --git a/src/omnimemory/models/memory/model_memory_item.py b/src/omnimemory/models/memory/model_memory_item.py
new file mode 100644
index 0000000..2bab9ef
--- /dev/null
+++ b/src/omnimemory/models/memory/model_memory_item.py
@@ -0,0 +1,162 @@
+"""
+Memory item model following ONEX standards.
+"""
+
+from __future__ import annotations
+
+from datetime import datetime
+from uuid import UUID
+
+from pydantic import BaseModel, Field, field_validator
+
+from ...enums.enum_memory_storage_type import EnumMemoryStorageType
+
+
+class ModelMemoryItem(BaseModel):
+    """A single memory item in the ONEX memory system."""
+
+    # Item identification
+    item_id: UUID = Field(
+        description="Unique identifier for the memory item",
+    )
+    item_type: str = Field(
+        description="Type or category of the memory item",
+    )
+
+    # Content
+    content: str = Field(
+        description="Main content of the memory item",
+    )
+    title: str | None = Field(
+        default=None,
+        description="Optional title for the memory item",
+    )
+    summary: str | None = Field(
+        default=None,
+        description="Optional summary of the content",
+    )
+
+    # Metadata
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Tags for categorizing the memory item",
+    )
+    keywords: list[str] = Field(
+        default_factory=list,
+        description="Keywords for search and indexing",
+    )
+
+    # Storage information
+    storage_type: EnumMemoryStorageType = Field(
+        description="Type of storage where this item is stored",
+    )
+    storage_location: str = Field(
+        description="Location identifier within the storage system",
+    )
+
+    # Versioning
+    version: int = Field(
+        default=1,
+        description="Version number of the memory item",
+    )
+    previous_version_id: UUID | None = Field(
+        default=None,
+        description="ID of the previous version if this is an update",
+    )
+
+    # Temporal information
+    created_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the memory item was created",
+    )
+    updated_at: datetime | None = Field(
+        default=None,
+        description="When the memory item was last updated",
+    )
+    expires_at: datetime | None = Field(
+        default=None,
+        description="When the memory item expires (optional)",
+    )
+
+    # Usage tracking
+    access_count: int = Field(
+        default=0,
+        description="Number of times this item has been accessed",
+    )
+    last_accessed_at: datetime | None = Field(
+        default=None,
+        description="When the memory item was last accessed",
+    )
+
+    # Quality indicators
+    importance_score: float = Field(
+        default=0.5,
+        ge=0.0,
+        le=1.0,
+        description="Importance score for prioritization",
+    )
+    relevance_score: float = Field(
+        default=0.5,
+        ge=0.0,
+        le=1.0,
+        description="Relevance score for search ranking",
+    )
+    quality_score: float = Field(
+        default=0.5,
+        ge=0.0,
+        le=1.0,
+        description="Quality score based on content analysis",
+    )
+
+    # Relationships
+    parent_item_id: UUID | None = Field(
+        default=None,
+        description="ID of parent item if this is part of a hierarchy",
+    )
+    related_item_ids: list[UUID] = Field(
+        default_factory=list,
+        description="IDs of related memory items",
+    )
+
+    # Processing status
+    processing_complete: bool = Field(
+        default=True,
+        description="Whether processing of this item is complete",
+    )
+    indexed: bool = Field(
+        default=False,
+        description="Whether this item has been indexed for search",
+    )
+
+    # Validation using Pydantic v2 syntax
+    @field_validator('content')
+    @classmethod
+    def validate_content_size(cls, v):
+        """Validate content size to prevent oversized memory items."""
+        MAX_CONTENT_SIZE = 1_000_000  # 1MB max content size
+        if len(v.encode('utf-8')) > MAX_CONTENT_SIZE:
+            raise ValueError(f"Content exceeds maximum size of {MAX_CONTENT_SIZE} bytes")
+        return v
+
+    @field_validator('title')
+    @classmethod
+    def validate_title_length(cls, v):
+        """Validate title length for reasonable limits."""
+        if v is not None:
+            MAX_TITLE_LENGTH = 500
+            if len(v) > MAX_TITLE_LENGTH:
+                raise ValueError(f"Title exceeds maximum length of {MAX_TITLE_LENGTH} characters")
+        return v
+
+    @field_validator('tags', 'keywords')
+    @classmethod
+    def validate_tag_limits(cls, v):
+        """Validate tag and keyword limits to prevent abuse."""
+        MAX_TAGS = 100
+        MAX_TAG_LENGTH = 100
+        if len(v) > MAX_TAGS:
+            raise ValueError(f"Cannot have more than {MAX_TAGS} tags/keywords")
+        for tag in v:
+            if len(tag) > MAX_TAG_LENGTH:
+                raise ValueError(f"Tag '{tag}' exceeds maximum length of {MAX_TAG_LENGTH} characters")
+        return v
\ No newline at end of file
diff --git a/src/omnimemory/models/memory/model_memory_query.py b/src/omnimemory/models/memory/model_memory_query.py
new file mode 100644
index 0000000..2fa5300
--- /dev/null
+++ b/src/omnimemory/models/memory/model_memory_query.py
@@ -0,0 +1,123 @@
+"""
+Memory query model following ONEX standards.
+"""
+
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+from ...enums.enum_memory_storage_type import EnumMemoryStorageType
+
+
+class ModelMemoryQuery(BaseModel):
+    """Query model for memory search and retrieval following ONEX standards."""
+
+    # Query identification
+    query_id: UUID = Field(
+        description="Unique identifier for the query",
+    )
+
+    # Query content
+    query_text: str = Field(
+        description="The main query text or search terms",
+    )
+    query_type: str = Field(
+        description="Type of query (semantic, keyword, structured, etc.)",
+    )
+
+    # Filters
+    item_types: list[str] = Field(
+        default_factory=list,
+        description="Filter by specific item types",
+    )
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Filter by tags",
+    )
+    keywords: list[str] = Field(
+        default_factory=list,
+        description="Filter by keywords",
+    )
+
+    # Storage targeting
+    storage_types: list[EnumMemoryStorageType] = Field(
+        default_factory=list,
+        description="Target specific storage types for the query",
+    )
+    storage_locations: list[str] = Field(
+        default_factory=list,
+        description="Target specific storage locations",
+    )
+
+    # Result parameters
+    limit: int = Field(
+        default=10,
+        ge=1,
+        le=1000,
+        description="Maximum number of results to return",
+    )
+    offset: int = Field(
+        default=0,
+        ge=0,
+        description="Number of results to skip (for pagination)",
+    )
+
+    # Scoring parameters
+    min_relevance_score: float = Field(
+        default=0.0,
+        ge=0.0,
+        le=1.0,
+        description="Minimum relevance score for results",
+    )
+    min_quality_score: float = Field(
+        default=0.0,
+        ge=0.0,
+        le=1.0,
+        description="Minimum quality score for results",
+    )
+    boost_recent: bool = Field(
+        default=False,
+        description="Whether to boost more recent items in scoring",
+    )
+    boost_popular: bool = Field(
+        default=False,
+        description="Whether to boost more frequently accessed items",
+    )
+
+    # Sorting
+    sort_by: str = Field(
+        default="relevance",
+        description="Field to sort results by",
+    )
+    sort_order: str = Field(
+        default="desc",
+        description="Sort order (asc or desc)",
+    )
+
+    # Options
+    include_metadata: bool = Field(
+        default=True,
+        description="Whether to include item metadata in results",
+    )
+    include_content: bool = Field(
+        default=True,
+        description="Whether to include full content in results",
+    )
+    highlight_matches: bool = Field(
+        default=False,
+        description="Whether to highlight search matches in content",
+    )
+
+    # Advanced options
+    semantic_search: bool = Field(
+        default=True,
+        description="Whether to use semantic search capabilities",
+    )
+    fuzzy_matching: bool = Field(
+        default=False,
+        description="Whether to use fuzzy matching for terms",
+    )
+    expand_query: bool = Field(
+        default=False,
+        description="Whether to expand query with related terms",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/memory/model_memory_search_result.py b/src/omnimemory/models/memory/model_memory_search_result.py
new file mode 100644
index 0000000..e4a1ae2
--- /dev/null
+++ b/src/omnimemory/models/memory/model_memory_search_result.py
@@ -0,0 +1,81 @@
+"""
+Memory search result model following ONEX standards.
+"""
+
+from uuid import UUID
+
+from pydantic import BaseModel, Field
+
+from .model_memory_item import ModelMemoryItem
+
+
+class ModelMemorySearchResult(BaseModel):
+    """Search result model for memory queries following ONEX standards."""
+
+    # Result identification
+    result_id: UUID = Field(
+        description="Unique identifier for this search result",
+    )
+    query_id: UUID = Field(
+        description="Identifier of the query that produced this result",
+    )
+
+    # Result content
+    memory_item: ModelMemoryItem = Field(
+        description="The memory item that matched the query",
+    )
+
+    # Scoring information
+    relevance_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Relevance score for this result",
+    )
+    confidence_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Confidence score for the match",
+    )
+    combined_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Combined score used for ranking",
+    )
+
+    # Match information
+    match_type: str = Field(
+        description="Type of match (exact, partial, semantic, etc.)",
+    )
+    matched_fields: list[str] = Field(
+        default_factory=list,
+        description="Fields that matched the query",
+    )
+    highlighted_content: str | None = Field(
+        default=None,
+        description="Content with search terms highlighted",
+    )
+
+    # Ranking information
+    rank: int = Field(
+        description="Position of this result in the result set",
+    )
+    total_results: int = Field(
+        description="Total number of results for the query",
+    )
+
+    # Processing metadata
+    processing_time_ms: float = Field(
+        description="Time taken to process this result",
+    )
+    storage_source: str = Field(
+        description="Storage system that provided this result",
+    )
+
+    # Quality indicators
+    match_quality: str = Field(
+        description="Quality of the match (high, medium, low)",
+    )
+    explanation: str | None = Field(
+        default=None,
+        description="Explanation of why this item matched",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/memory/model_memory_storage_config.py b/src/omnimemory/models/memory/model_memory_storage_config.py
new file mode 100644
index 0000000..14cb874
--- /dev/null
+++ b/src/omnimemory/models/memory/model_memory_storage_config.py
@@ -0,0 +1,126 @@
+"""
+Memory storage configuration model following ONEX standards.
+"""
+
+from __future__ import annotations
+
+from pydantic import BaseModel, Field, SecretStr, field_validator
+
+from ...enums.enum_memory_storage_type import EnumMemoryStorageType
+
+
+class ModelMemoryStorageConfig(BaseModel):
+    """Configuration for memory storage systems following ONEX standards."""
+
+    # Storage identification
+    storage_id: str = Field(
+        description="Unique identifier for the storage system",
+    )
+    storage_name: str = Field(
+        description="Human-readable name for the storage system",
+    )
+    storage_type: EnumMemoryStorageType = Field(
+        description="Type of storage system",
+    )
+
+    # Connection configuration
+    connection_string: str = Field(
+        description="Connection string for the storage system",
+    )
+    host: str = Field(
+        description="Host address for the storage system",
+    )
+    port: int = Field(
+        description="Port number for the storage system",
+    )
+    database_name: str = Field(
+        description="Name of the database or collection",
+    )
+
+    # Authentication
+    username: str | None = Field(
+        default=None,
+        description="Username for authentication",
+    )
+    password_hash: SecretStr | None = Field(
+        default=None,
+        description="Hashed password for authentication - protected with SecretStr",
+        exclude=True,  # Never serialize sensitive data
+    )
+    api_key: SecretStr | None = Field(
+        default=None,
+        description="API key for authentication - protected with SecretStr",
+        exclude=True,  # Never serialize sensitive data
+    )
+
+    # Connection pool settings
+    max_connections: int = Field(
+        default=10,
+        description="Maximum number of concurrent connections",
+    )
+    connection_timeout_ms: int = Field(
+        default=5000,
+        description="Connection timeout in milliseconds",
+    )
+    idle_timeout_ms: int = Field(
+        default=30000,
+        description="Idle connection timeout in milliseconds",
+    )
+
+    # Performance settings
+    batch_size: int = Field(
+        default=100,
+        description="Default batch size for operations",
+    )
+    enable_compression: bool = Field(
+        default=True,
+        description="Whether to enable data compression",
+    )
+    enable_encryption: bool = Field(
+        default=True,
+        description="Whether to enable data encryption",
+    )
+
+    # Operational settings
+    enable_metrics: bool = Field(
+        default=True,
+        description="Whether to collect performance metrics",
+    )
+    enable_logging: bool = Field(
+        default=True,
+        description="Whether to enable operation logging",
+    )
+    backup_enabled: bool = Field(
+        default=False,
+        description="Whether automatic backups are enabled",
+    )
+
+    @field_validator('max_connections')
+    @classmethod
+    def validate_max_connections(cls, v: int) -> int:
+        """Validate max_connections is within reasonable bounds."""
+        if v < 1:
+            raise ValueError('max_connections must be at least 1')
+        if v > 1000:
+            raise ValueError('max_connections cannot exceed 1000')
+        return v
+
+    @field_validator('connection_timeout_ms', 'idle_timeout_ms')
+    @classmethod
+    def validate_timeout_values(cls, v: int) -> int:
+        """Validate timeout values are positive and reasonable."""
+        if v < 100:
+            raise ValueError('Timeout values must be at least 100ms')
+        if v > 300000:  # 5 minutes
+            raise ValueError('Timeout values cannot exceed 300,000ms (5 minutes)')
+        return v
+
+    @field_validator('batch_size')
+    @classmethod
+    def validate_batch_size(cls, v: int) -> int:
+        """Validate batch size is within reasonable bounds."""
+        if v < 1:
+            raise ValueError('batch_size must be at least 1')
+        if v > 10000:
+            raise ValueError('batch_size cannot exceed 10,000')
+        return v
\ No newline at end of file
diff --git a/src/omnimemory/models/service/__init__.py b/src/omnimemory/models/service/__init__.py
new file mode 100644
index 0000000..17401f7
--- /dev/null
+++ b/src/omnimemory/models/service/__init__.py
@@ -0,0 +1,18 @@
+"""
+Service domain models for OmniMemory following ONEX standards.
+
+This module provides models for service configurations, orchestration,
+and coordination in the ONEX 4-node architecture.
+"""
+
+from omnibase_core.enums.node import EnumHealthStatus
+from .model_service_config import ModelServiceConfig
+from .model_service_health import ModelServiceHealth
+from .model_service_registry import ModelServiceRegistry
+
+__all__ = [
+    "EnumHealthStatus",
+    "ModelServiceConfig",
+    "ModelServiceHealth",
+    "ModelServiceRegistry",
+]
\ No newline at end of file
diff --git a/src/omnimemory/models/service/model_service_config.py b/src/omnimemory/models/service/model_service_config.py
new file mode 100644
index 0000000..e997e60
--- /dev/null
+++ b/src/omnimemory/models/service/model_service_config.py
@@ -0,0 +1,147 @@
+"""
+Service configuration model following ONEX standards.
+"""
+
+from pydantic import BaseModel, Field
+
+from omnibase_core.enums.node import EnumNodeType
+from omnibase_core.enums.node import EnumHealthStatus
+
+
+class ModelServiceConfig(BaseModel):
+    """Configuration for ONEX memory services following standards."""
+
+    # Service identification
+    service_id: str = Field(
+        description="Unique identifier for the service",
+    )
+    service_name: str = Field(
+        description="Human-readable name for the service",
+    )
+    service_type: str = Field(
+        description="Type of service (storage, retrieval, processing, etc.)",
+    )
+
+    # ONEX architecture information
+    node_type: EnumNodeType = Field(
+        description="ONEX node type for this service",
+    )
+    node_priority: int = Field(
+        default=5,
+        ge=1,
+        le=10,
+        description="Priority of this service within its node type",
+    )
+
+    # Service configuration
+    host: str = Field(
+        description="Host address for the service",
+    )
+    port: int = Field(
+        description="Port number for the service",
+    )
+    endpoint: str = Field(
+        description="Service endpoint path",
+    )
+
+    # Resource configuration
+    max_memory_mb: int = Field(
+        default=1024,
+        description="Maximum memory allocation in megabytes",
+    )
+    max_cpu_percent: int = Field(
+        default=80,
+        description="Maximum CPU usage percentage",
+    )
+    max_connections: int = Field(
+        default=100,
+        description="Maximum number of concurrent connections",
+    )
+
+    # Timeout configuration
+    request_timeout_ms: int = Field(
+        default=30000,
+        description="Request timeout in milliseconds",
+    )
+    health_check_timeout_ms: int = Field(
+        default=5000,
+        description="Health check timeout in milliseconds",
+    )
+    shutdown_timeout_ms: int = Field(
+        default=10000,
+        description="Graceful shutdown timeout in milliseconds",
+    )
+
+    # Retry configuration
+    max_retries: int = Field(
+        default=3,
+        description="Maximum number of retry attempts",
+    )
+    retry_delay_ms: int = Field(
+        default=1000,
+        description="Delay between retry attempts in milliseconds",
+    )
+    exponential_backoff: bool = Field(
+        default=True,
+        description="Whether to use exponential backoff for retries",
+    )
+
+    # Monitoring configuration
+    enable_metrics: bool = Field(
+        default=True,
+        description="Whether to enable metrics collection",
+    )
+    enable_logging: bool = Field(
+        default=True,
+        description="Whether to enable detailed logging",
+    )
+    enable_tracing: bool = Field(
+        default=False,
+        description="Whether to enable distributed tracing",
+    )
+
+    # Security configuration
+    require_authentication: bool = Field(
+        default=True,
+        description="Whether authentication is required",
+    )
+    require_authorization: bool = Field(
+        default=True,
+        description="Whether authorization is required",
+    )
+    enable_tls: bool = Field(
+        default=True,
+        description="Whether to enable TLS encryption",
+    )
+
+    # Service dependencies
+    dependencies: list[str] = Field(
+        default_factory=list,
+        description="List of service dependencies",
+    )
+    optional_dependencies: list[str] = Field(
+        default_factory=list,
+        description="List of optional service dependencies",
+    )
+
+    # Environment configuration
+    environment: str = Field(
+        default="production",
+        description="Environment (development, staging, production)",
+    )
+    region: str = Field(
+        default="us-west-2",
+        description="Deployment region",
+    )
+
+    # Feature flags
+    feature_flags: dict[str, bool] = Field(
+        default_factory=dict,
+        description="Feature flags for the service",
+    )
+
+    # Additional configuration
+    custom_config: dict[str, str] = Field(
+        default_factory=dict,
+        description="Custom configuration parameters",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/service/model_service_health.py b/src/omnimemory/models/service/model_service_health.py
new file mode 100644
index 0000000..21a66b6
--- /dev/null
+++ b/src/omnimemory/models/service/model_service_health.py
@@ -0,0 +1,133 @@
+"""
+Service health model following ONEX standards.
+"""
+
+from datetime import datetime
+
+from pydantic import BaseModel, Field
+
+from omnibase_core.enums.node import EnumHealthStatus
+
+
+class ModelServiceHealth(BaseModel):
+    """Service health information following ONEX standards."""
+
+    # Service identification
+    service_id: str = Field(
+        description="Unique identifier for the service",
+    )
+    service_name: str = Field(
+        description="Human-readable name for the service",
+    )
+
+    # Health status
+    status: EnumHealthStatus = Field(
+        description="Current status of the service",
+    )
+    is_healthy: bool = Field(
+        description="Whether the service is considered healthy",
+    )
+
+    # Uptime information
+    uptime_seconds: int = Field(
+        description="Service uptime in seconds",
+    )
+    last_restart_at: datetime | None = Field(
+        default=None,
+        description="When the service was last restarted",
+    )
+
+    # Performance metrics
+    response_time_ms: float = Field(
+        description="Average response time in milliseconds",
+    )
+    requests_per_second: float = Field(
+        description="Current requests per second",
+    )
+    error_rate: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Error rate as a percentage",
+    )
+
+    # Resource utilization
+    cpu_usage_percent: float = Field(
+        ge=0.0,
+        le=100.0,
+        description="Current CPU usage percentage",
+    )
+    memory_usage_mb: float = Field(
+        description="Current memory usage in megabytes",
+    )
+    memory_usage_percent: float = Field(
+        ge=0.0,
+        le=100.0,
+        description="Memory usage as percentage of allocated",
+    )
+
+    # Connection information
+    active_connections: int = Field(
+        description="Number of active connections",
+    )
+    max_connections: int = Field(
+        description="Maximum allowed connections",
+    )
+    connection_pool_utilization: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Connection pool utilization percentage",
+    )
+
+    # Dependency health
+    dependencies_healthy: bool = Field(
+        description="Whether all dependencies are healthy",
+    )
+    unhealthy_dependencies: list[str] = Field(
+        default_factory=list,
+        description="List of unhealthy dependencies",
+    )
+
+    # Error information
+    recent_errors: list[str] = Field(
+        default_factory=list,
+        description="List of recent error messages",
+    )
+    critical_errors: int = Field(
+        default=0,
+        description="Number of critical errors in the last hour",
+    )
+
+    # Health check information
+    last_health_check: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the health check was performed",
+    )
+    health_check_duration_ms: float = Field(
+        description="Duration of the health check in milliseconds",
+    )
+
+    # Service-specific metrics
+    custom_metrics: dict[str, float] = Field(
+        default_factory=dict,
+        description="Service-specific health metrics",
+    )
+
+    # Alerts and warnings
+    active_alerts: list[str] = Field(
+        default_factory=list,
+        description="List of active alerts",
+    )
+    warnings: list[str] = Field(
+        default_factory=list,
+        description="List of current warnings",
+    )
+
+    # Trend information
+    health_trend: str = Field(
+        default="stable",
+        description="Health trend (improving, stable, degrading)",
+    )
+    performance_trend: str = Field(
+        default="stable",
+        description="Performance trend (improving, stable, degrading)",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/models/service/model_service_registry.py b/src/omnimemory/models/service/model_service_registry.py
new file mode 100644
index 0000000..cbcf829
--- /dev/null
+++ b/src/omnimemory/models/service/model_service_registry.py
@@ -0,0 +1,135 @@
+"""
+Service registry model following ONEX standards.
+"""
+
+from datetime import datetime
+
+from pydantic import BaseModel, Field
+
+from omnibase_core.enums.node import EnumNodeType
+from omnibase_core.enums.node import EnumHealthStatus
+
+
+class ModelServiceRegistry(BaseModel):
+    """Service registry entry following ONEX standards."""
+
+    # Service identification
+    service_id: str = Field(
+        description="Unique identifier for the service",
+    )
+    service_name: str = Field(
+        description="Human-readable name for the service",
+    )
+    service_version: str = Field(
+        description="Version of the service",
+    )
+
+    # Service location
+    host: str = Field(
+        description="Host address for the service",
+    )
+    port: int = Field(
+        description="Port number for the service",
+    )
+    endpoint: str = Field(
+        description="Service endpoint path",
+    )
+    protocol: str = Field(
+        default="https",
+        description="Protocol used by the service",
+    )
+
+    # ONEX architecture information
+    node_type: EnumNodeType = Field(
+        description="ONEX node type for this service",
+    )
+    capabilities: list[str] = Field(
+        default_factory=list,
+        description="Capabilities provided by this service",
+    )
+
+    # Service status
+    status: EnumHealthStatus = Field(
+        description="Current status of the service",
+    )
+    is_available: bool = Field(
+        description="Whether the service is available for requests",
+    )
+
+    # Registration information
+    registered_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="When the service was registered",
+    )
+    last_heartbeat: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="Last heartbeat from the service",
+    )
+    heartbeat_interval_ms: int = Field(
+        default=30000,
+        description="Expected heartbeat interval in milliseconds",
+    )
+
+    # Service metadata
+    tags: list[str] = Field(
+        default_factory=list,
+        description="Tags for categorizing the service",
+    )
+    metadata: dict[str, str] = Field(
+        default_factory=dict,
+        description="Additional metadata for the service",
+    )
+
+    # Load balancing information
+    weight: int = Field(
+        default=1,
+        description="Weight for load balancing (higher = more traffic)",
+    )
+    max_load: int = Field(
+        default=100,
+        description="Maximum load this service can handle",
+    )
+    current_load: int = Field(
+        default=0,
+        description="Current load on the service",
+    )
+
+    # Health information
+    health_check_url: str = Field(
+        description="URL for health checks",
+    )
+    last_health_check: datetime | None = Field(
+        default=None,
+        description="When the last health check was performed",
+    )
+    health_status: str = Field(
+        default="unknown",
+        description="Result of the last health check",
+    )
+
+    # Circuit breaker information
+    circuit_breaker_state: str = Field(
+        default="closed",
+        description="State of the circuit breaker (closed, open, half-open)",
+    )
+    failure_count: int = Field(
+        default=0,
+        description="Number of consecutive failures",
+    )
+    failure_threshold: int = Field(
+        default=5,
+        description="Failure threshold for circuit breaker",
+    )
+
+    # Discovery information
+    discovery_method: str = Field(
+        description="How the service was discovered",
+    )
+    auto_deregister: bool = Field(
+        default=True,
+        description="Whether to auto-deregister if health checks fail",
+    )
+    ttl_seconds: int = Field(
+        default=300,
+        description="Time to live for the registration",
+    )
\ No newline at end of file
diff --git a/src/omnimemory/protocols/__init__.py b/src/omnimemory/protocols/__init__.py
new file mode 100644
index 0000000..5a2c8cf
--- /dev/null
+++ b/src/omnimemory/protocols/__init__.py
@@ -0,0 +1,137 @@
+"""
+OmniMemory Protocol Definitions
+
+This module contains all protocol definitions for the OmniMemory system,
+following ONEX 4-node architecture patterns and contract-driven development.
+
+All protocols use typing.Protocol for structural typing and avoid isinstance
+checks, supporting the ModelOnexContainer pattern for dependency injection.
+"""
+
+from .base_protocols import (
+    # Base protocols
+    ProtocolMemoryBase,
+    ProtocolMemoryOperations,
+    
+    # Effect node protocols (memory storage, retrieval, persistence)
+    ProtocolMemoryStorage,
+    ProtocolMemoryRetrieval, 
+    ProtocolMemoryPersistence,
+    
+    # Compute node protocols (intelligence processing, semantic analysis)
+    ProtocolIntelligenceProcessor,
+    ProtocolSemanticAnalyzer,
+    ProtocolPatternRecognition,
+    
+    # Reducer node protocols (consolidation, aggregation, optimization)
+    ProtocolMemoryConsolidator,
+    ProtocolMemoryAggregator,
+    ProtocolMemoryOptimizer,
+    
+    # Orchestrator node protocols (workflow, agent, memory coordination)
+    ProtocolWorkflowCoordinator,
+    ProtocolAgentCoordinator,
+    ProtocolMemoryOrchestrator,
+)
+
+from .data_models import (
+    # Core data models
+    BaseMemoryRequest,
+    BaseMemoryResponse,
+    MemoryRecord,
+    UserContext,
+    StoragePreferences,
+    SearchFilters,
+    SearchResult,
+    
+    # Request/Response models
+    MemoryStoreRequest,
+    MemoryStoreResponse,
+    MemoryRetrieveRequest, 
+    MemoryRetrieveResponse,
+    SemanticSearchRequest,
+    SemanticSearchResponse,
+    TemporalSearchRequest,
+    TemporalSearchResponse,
+    
+    # Enums
+    OperationStatus,
+    ContentType,
+    MemoryPriority,
+    AccessLevel,
+    IndexingStatus,
+)
+
+from .error_models import (
+    # Error handling
+    OmniMemoryError,
+    ValidationError,
+    StorageError,
+    RetrievalError,
+    ProcessingError,
+    CoordinationError,
+    SystemError,
+    
+    # Error codes
+    OmniMemoryErrorCode,
+)
+
+__all__ = [
+    # Base protocols
+    "ProtocolMemoryBase",
+    "ProtocolMemoryOperations",
+    
+    # Effect node protocols
+    "ProtocolMemoryStorage",
+    "ProtocolMemoryRetrieval",
+    "ProtocolMemoryPersistence",
+    
+    # Compute node protocols  
+    "ProtocolIntelligenceProcessor",
+    "ProtocolSemanticAnalyzer",
+    "ProtocolPatternRecognition",
+    
+    # Reducer node protocols
+    "ProtocolMemoryConsolidator", 
+    "ProtocolMemoryAggregator",
+    "ProtocolMemoryOptimizer",
+    
+    # Orchestrator node protocols
+    "ProtocolWorkflowCoordinator",
+    "ProtocolAgentCoordinator", 
+    "ProtocolMemoryOrchestrator",
+    
+    # Data models
+    "BaseMemoryRequest",
+    "BaseMemoryResponse", 
+    "MemoryRecord",
+    "UserContext",
+    "StoragePreferences",
+    "SearchFilters",
+    "SearchResult",
+    "MemoryStoreRequest",
+    "MemoryStoreResponse",
+    "MemoryRetrieveRequest",
+    "MemoryRetrieveResponse", 
+    "SemanticSearchRequest",
+    "SemanticSearchResponse",
+    "TemporalSearchRequest",
+    "TemporalSearchResponse",
+    
+    # Enums
+    "OperationStatus",
+    "ContentType", 
+    "MemoryPriority",
+    "AccessLevel",
+    "IndexingStatus",
+    
+    # Error handling
+    "OmniMemoryError",
+    "ValidationError",
+    "StorageError", 
+    "RetrievalError",
+    "ProcessingError",
+    "CoordinationError",
+    "SystemError",
+    "OmniMemoryErrorCode",
+]
\ No newline at end of file
diff --git a/src/omnimemory/protocols/base_protocols.py b/src/omnimemory/protocols/base_protocols.py
new file mode 100644
index 0000000..0af2d3c
--- /dev/null
+++ b/src/omnimemory/protocols/base_protocols.py
@@ -0,0 +1,1171 @@
+"""
+Base Protocol Definitions for OmniMemory ONEX Architecture
+
+This module defines all protocol interfaces following ONEX 4-node architecture:
+- Effect: Memory storage, retrieval, and persistence operations
+- Compute: Intelligence processing, semantic analysis, pattern recognition
+- Reducer: Memory consolidation, aggregation, and optimization
+- Orchestrator: Workflow, agent, and memory coordination
+
+All protocols use typing.Protocol for structural typing, avoiding isinstance
+checks and supporting ModelOnexContainer dependency injection patterns.
+"""
+
+from __future__ import annotations
+
+from abc import abstractmethod
+from datetime import datetime
+from typing import Optional, Protocol
+from uuid import UUID
+
+from omnibase_core.core.monadic.model_node_result import NodeResult
+
+from ..models.foundation import (
+    ModelHealthResponse,
+    ModelMetricsResponse,
+    ModelStringList,
+    ModelOptionalStringList,
+    ModelMetadata,
+    ModelConfiguration,
+    ModelResultCollection,
+    ModelSystemConfiguration
+)
+
+from .data_models import (
+    # Requests and responses
+    BaseMemoryRequest,
+    BaseMemoryResponse,
+    MemoryRecord,
+    MemoryStoreRequest,
+    MemoryStoreResponse,
+    MemoryRetrieveRequest,
+    MemoryRetrieveResponse,
+    MemoryDeleteRequest,
+    MemoryDeleteResponse,
+    SemanticSearchRequest,
+    SemanticSearchResponse,
+    TemporalSearchRequest,
+    TemporalSearchResponse,
+    ContextualSearchRequest,
+    ContextualSearchResponse,
+    PersistenceRequest,
+    PersistenceResponse,
+    BackupRequest,
+    BackupResponse,
+    RestoreRequest,
+    RestoreResponse,
+    IntelligenceProcessRequest,
+    IntelligenceProcessResponse,
+    PatternAnalysisRequest,
+    PatternAnalysisResponse,
+    InsightExtractionRequest,
+    InsightExtractionResponse,
+    SemanticAnalysisRequest,
+    SemanticAnalysisResponse,
+    EmbeddingRequest,
+    EmbeddingResponse,
+    SemanticComparisonRequest,
+    SemanticComparisonResponse,
+    PatternRecognitionRequest,
+    PatternRecognitionResponse,
+    PatternLearningRequest,
+    PatternLearningResponse,
+    PatternPredictionRequest,
+    PatternPredictionResponse,
+    ConsolidationRequest,
+    ConsolidationResponse,
+    DeduplicationRequest,
+    DeduplicationResponse,
+    ContextMergeRequest,
+    ContextMergeResponse,
+    AggregationRequest,
+    AggregationResponse,
+    SummarizationRequest,
+    SummarizationResponse,
+    StatisticsRequest,
+    StatisticsResponse,
+    LayoutOptimizationRequest,
+    LayoutOptimizationResponse,
+    CompressionRequest,
+    CompressionResponse,
+    RetrievalOptimizationRequest,
+    RetrievalOptimizationResponse,
+    WorkflowExecutionRequest,
+    WorkflowExecutionResponse,
+    ParallelCoordinationRequest,
+    ParallelCoordinationResponse,
+    WorkflowStateRequest,
+    WorkflowStateResponse,
+    AgentCoordinationRequest,
+    AgentCoordinationResponse,
+    BroadcastRequest,
+    BroadcastResponse,
+    StateSynchronizationRequest,
+    StateSynchronizationResponse,
+    LifecycleOrchestrationRequest,
+    LifecycleOrchestrationResponse,
+    QuotaManagementRequest,
+    QuotaManagementResponse,
+    MigrationCoordinationRequest,
+    MigrationCoordinationResponse,
+)
+
+
+# === BASE PROTOCOLS ===
+
+
+class ProtocolMemoryBase(Protocol):
+    """
+    Base protocol for all memory-related operations.
+    
+    Provides foundational capabilities that all memory components must implement,
+    including health checking, configuration management, and basic observability.
+    """
+    
+    @abstractmethod
+    async def health_check(
+        self,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelHealthResponse]:
+        """
+        Check the health status of the memory component.
+
+        Returns:
+            NodeResult containing ModelHealthResponse with:
+            - status: overall system health (healthy/degraded/unhealthy)
+            - latency_ms: response time metrics
+            - resource_usage: detailed system resource metrics
+            - dependencies: status of external dependencies
+            - uptime, version, environment details
+        """
+        ...
+    
+    @abstractmethod
+    async def get_metrics(
+        self,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetricsResponse]:
+        """
+        Get operational metrics for the memory component.
+
+        Returns:
+            NodeResult containing ModelMetricsResponse with:
+            - operation_counts: detailed counts by operation type
+            - performance_metrics: latency, throughput, error rates
+            - resource_metrics: memory usage, cache statistics, connections
+            - custom_metrics: application-specific measurements
+            - alerts: active performance warnings
+        """
+        ...
+    
+    @abstractmethod
+    async def configure(
+        self,
+        config: ModelSystemConfiguration,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[bool]:
+        """
+        Configure the memory component with new settings.
+
+        Args:
+            config: ModelSystemConfiguration with database, cache, performance,
+                   and observability settings
+            correlation_id: Request correlation ID
+
+        Returns:
+            NodeResult indicating configuration success/failure
+        """
+        ...
+
+
+class ProtocolMemoryOperations(ProtocolMemoryBase, Protocol):
+    """
+    Base protocol for memory operations with common patterns.
+    
+    Extends ProtocolMemoryBase with standard CRUD operations that most
+    memory components will need to implement.
+    """
+    
+    @abstractmethod
+    async def validate_request(
+        self,
+        request: BaseMemoryRequest,
+    ) -> NodeResult[bool]:
+        """
+        Validate a memory operation request.
+        
+        Args:
+            request: The request to validate
+            
+        Returns:
+            NodeResult indicating validation success/failure with error details
+        """
+        ...
+    
+    @abstractmethod
+    async def log_operation(
+        self,
+        operation: str,
+        request: BaseMemoryRequest,
+        response: BaseMemoryResponse,
+        correlation_id: UUID,
+    ) -> NodeResult[bool]:
+        """
+        Log a completed memory operation for audit and monitoring.
+        
+        Args:
+            operation: Operation name
+            request: Original request
+            response: Operation response  
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult indicating logging success/failure
+        """
+        ...
+
+
+# === EFFECT NODE PROTOCOLS ===
+
+
+class ProtocolMemoryStorage(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for memory storage operations (Effect node).
+    
+    Handles the storage of memory records with metadata, provenance tracking,
+    and support for different storage backends (PostgreSQL, Redis, etc.).
+    """
+    
+    @abstractmethod
+    async def store_memory(
+        self,
+        request: MemoryStoreRequest,
+    ) -> NodeResult[MemoryStoreResponse]:
+        """
+        Store a memory record with metadata and provenance.
+        
+        Args:
+            request: Memory storage request containing the memory record
+            
+        Returns:
+            NodeResult with MemoryStoreResponse containing storage details
+        """
+        ...
+    
+    @abstractmethod
+    async def retrieve_memory(
+        self,
+        request: MemoryRetrieveRequest,
+    ) -> NodeResult[MemoryRetrieveResponse]:
+        """
+        Retrieve a memory record by identifier.
+        
+        Args:
+            request: Memory retrieval request with memory ID
+            
+        Returns:
+            NodeResult with MemoryRetrieveResponse containing the memory record
+        """
+        ...
+    
+    @abstractmethod
+    async def delete_memory(
+        self,
+        request: MemoryDeleteRequest,
+    ) -> NodeResult[MemoryDeleteResponse]:
+        """
+        Soft delete a memory record with audit trail.
+        
+        Args:
+            request: Memory deletion request with memory ID
+            
+        Returns:
+            NodeResult with MemoryDeleteResponse indicating success/failure
+        """
+        ...
+    
+    @abstractmethod
+    async def update_memory(
+        self,
+        memory_id: UUID,
+        updates: ModelMetadata,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[MemoryRecord]:
+        """
+        Update an existing memory record.
+        
+        Args:
+            memory_id: ID of memory to update
+            updates: Dictionary of fields to update
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with updated MemoryRecord
+        """
+        ...
+    
+    @abstractmethod
+    async def list_memories(
+        self,
+        filters: Optional[ModelMetadata] = None,
+        limit: int = 100,
+        offset: int = 0,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[List[MemoryRecord]]:
+        """
+        List memory records with optional filtering and pagination.
+        
+        Args:
+            filters: Optional filters to apply
+            limit: Maximum number of records to return
+            offset: Number of records to skip
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with list of MemoryRecord objects
+        """
+        ...
+
+
+class ProtocolMemoryRetrieval(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for advanced memory retrieval operations (Effect node).
+    
+    Provides semantic search, temporal search, and contextual retrieval
+    capabilities using vector embeddings and time-based indexing.
+    """
+    
+    @abstractmethod
+    async def semantic_search(
+        self,
+        request: SemanticSearchRequest,
+    ) -> NodeResult[SemanticSearchResponse]:
+        """
+        Perform vector-based semantic similarity search.
+        
+        Args:
+            request: Semantic search request with query and parameters
+            
+        Returns:
+            NodeResult with SemanticSearchResponse containing matched memories
+        """
+        ...
+    
+    @abstractmethod
+    async def temporal_search(
+        self,
+        request: TemporalSearchRequest,
+    ) -> NodeResult[TemporalSearchResponse]:
+        """
+        Perform time-based memory retrieval with decay consideration.
+        
+        Args:
+            request: Temporal search request with time range and criteria
+            
+        Returns:
+            NodeResult with TemporalSearchResponse containing time-filtered memories
+        """
+        ...
+    
+    @abstractmethod
+    async def contextual_search(
+        self,
+        request: ContextualSearchRequest,
+    ) -> NodeResult[ContextualSearchResponse]:
+        """
+        Perform context-aware memory retrieval using multiple criteria.
+        
+        Args:
+            request: Contextual search request with context parameters
+            
+        Returns:
+            NodeResult with ContextualSearchResponse containing context-matched memories
+        """
+        ...
+    
+    @abstractmethod
+    async def get_related_memories(
+        self,
+        memory_id: UUID,
+        relationship_types: Optional[ModelOptionalStringList] = None,
+        max_depth: int = 2,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[List[MemoryRecord]]:
+        """
+        Get memories related to a specific memory record.
+        
+        Args:
+            memory_id: ID of the source memory
+            relationship_types: Types of relationships to follow
+            max_depth: Maximum relationship depth to traverse
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with list of related MemoryRecord objects
+        """
+        ...
+
+
+class ProtocolMemoryPersistence(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for memory persistence and durability management (Effect node).
+    
+    Handles long-term storage, backup/restore operations, and data durability
+    across different storage systems and failure scenarios.
+    """
+    
+    @abstractmethod
+    async def persist_to_storage(
+        self,
+        request: PersistenceRequest,
+    ) -> NodeResult[PersistenceResponse]:
+        """
+        Persist memory data to durable storage.
+        
+        Args:
+            request: Persistence request with storage preferences
+            
+        Returns:
+            NodeResult with PersistenceResponse containing storage details
+        """
+        ...
+    
+    @abstractmethod
+    async def backup_memory(
+        self,
+        request: BackupRequest,
+    ) -> NodeResult[BackupResponse]:
+        """
+        Create a backup of memory data with versioning.
+        
+        Args:
+            request: Backup request with backup parameters
+            
+        Returns:
+            NodeResult with BackupResponse containing backup details
+        """
+        ...
+    
+    @abstractmethod
+    async def restore_memory(
+        self,
+        request: RestoreRequest,
+    ) -> NodeResult[RestoreResponse]:
+        """
+        Restore memory data from a backup.
+        
+        Args:
+            request: Restore request with backup identifier and options
+            
+        Returns:
+            NodeResult with RestoreResponse containing restore status
+        """
+        ...
+    
+    @abstractmethod
+    async def verify_integrity(
+        self,
+        memory_ids: Optional[List[UUID]] = None,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Verify the integrity of stored memory data.
+        
+        Args:
+            memory_ids: Optional list of specific memory IDs to verify
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with integrity verification results
+        """
+        ...
+
+
+# === COMPUTE NODE PROTOCOLS ===
+
+
+class ProtocolIntelligenceProcessor(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for intelligence processing operations (Compute node).
+    
+    Processes raw intelligence data into structured memory records,
+    extracts insights, and performs pattern analysis.
+    """
+    
+    @abstractmethod
+    async def process_intelligence(
+        self,
+        request: IntelligenceProcessRequest,
+    ) -> NodeResult[IntelligenceProcessResponse]:
+        """
+        Process raw intelligence data into structured memory.
+        
+        Args:
+            request: Intelligence processing request with raw data
+            
+        Returns:
+            NodeResult with IntelligenceProcessResponse containing processed data
+        """
+        ...
+    
+    @abstractmethod
+    async def analyze_patterns(
+        self,
+        request: PatternAnalysisRequest,
+    ) -> NodeResult[PatternAnalysisResponse]:
+        """
+        Analyze patterns in intelligence data.
+        
+        Args:
+            request: Pattern analysis request with data to analyze
+            
+        Returns:
+            NodeResult with PatternAnalysisResponse containing discovered patterns
+        """
+        ...
+    
+    @abstractmethod
+    async def extract_insights(
+        self,
+        request: InsightExtractionRequest,
+    ) -> NodeResult[InsightExtractionResponse]:
+        """
+        Extract actionable insights from processed intelligence.
+        
+        Args:
+            request: Insight extraction request with processed data
+            
+        Returns:
+            NodeResult with InsightExtractionResponse containing extracted insights
+        """
+        ...
+    
+    @abstractmethod
+    async def enrich_memory(
+        self,
+        memory: MemoryRecord,
+        enrichment_types: ModelStringList,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[MemoryRecord]:
+        """
+        Enrich a memory record with additional intelligence data.
+        
+        Args:
+            memory: Memory record to enrich
+            enrichment_types: Types of enrichment to apply
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with enriched MemoryRecord
+        """
+        ...
+
+
+class ProtocolSemanticAnalyzer(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for semantic analysis and understanding (Compute node).
+    
+    Provides semantic analysis, vector embedding generation, and
+    semantic similarity comparison capabilities.
+    """
+    
+    @abstractmethod
+    async def analyze_semantics(
+        self,
+        request: SemanticAnalysisRequest,
+    ) -> NodeResult[SemanticAnalysisResponse]:
+        """
+        Analyze semantic content and relationships.
+        
+        Args:
+            request: Semantic analysis request with content to analyze
+            
+        Returns:
+            NodeResult with SemanticAnalysisResponse containing analysis results
+        """
+        ...
+    
+    @abstractmethod
+    async def generate_embeddings(
+        self,
+        request: EmbeddingRequest,
+    ) -> NodeResult[EmbeddingResponse]:
+        """
+        Generate vector embeddings for semantic search.
+        
+        Args:
+            request: Embedding request with text to embed
+            
+        Returns:
+            NodeResult with EmbeddingResponse containing vector embeddings
+        """
+        ...
+    
+    @abstractmethod
+    async def compare_semantics(
+        self,
+        request: SemanticComparisonRequest,
+    ) -> NodeResult[SemanticComparisonResponse]:
+        """
+        Compare semantic similarity between content.
+        
+        Args:
+            request: Semantic comparison request with content to compare
+            
+        Returns:
+            NodeResult with SemanticComparisonResponse containing similarity scores
+        """
+        ...
+    
+    @abstractmethod
+    async def cluster_content(
+        self,
+        content_items: ModelStringList,
+        num_clusters: Optional[int] = None,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Cluster content items by semantic similarity.
+        
+        Args:
+            content_items: List of content to cluster
+            num_clusters: Optional number of clusters to create
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with clustering results
+        """
+        ...
+
+
+class ProtocolPatternRecognition(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for pattern recognition and learning (Compute node).
+    
+    Recognizes patterns in memory data, learns from historical patterns,
+    and makes predictions based on learned patterns.
+    """
+    
+    @abstractmethod
+    async def recognize_patterns(
+        self,
+        request: PatternRecognitionRequest,
+    ) -> NodeResult[PatternRecognitionResponse]:
+        """
+        Recognize patterns in memory data.
+        
+        Args:
+            request: Pattern recognition request with data to analyze
+            
+        Returns:
+            NodeResult with PatternRecognitionResponse containing recognized patterns
+        """
+        ...
+    
+    @abstractmethod
+    async def learn_patterns(
+        self,
+        request: PatternLearningRequest,
+    ) -> NodeResult[PatternLearningResponse]:
+        """
+        Learn new patterns from memory data.
+        
+        Args:
+            request: Pattern learning request with training data
+            
+        Returns:
+            NodeResult with PatternLearningResponse containing learning results
+        """
+        ...
+    
+    @abstractmethod
+    async def predict_patterns(
+        self,
+        request: PatternPredictionRequest,
+    ) -> NodeResult[PatternPredictionResponse]:
+        """
+        Predict future patterns based on learned data.
+        
+        Args:
+            request: Pattern prediction request with context data
+            
+        Returns:
+            NodeResult with PatternPredictionResponse containing predictions
+        """
+        ...
+    
+    @abstractmethod
+    async def validate_patterns(
+        self,
+        patterns: ModelResultCollection,
+        validation_data: ModelResultCollection,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Validate discovered patterns against validation data.
+        
+        Args:
+            patterns: Patterns to validate
+            validation_data: Data to validate patterns against
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with pattern validation results
+        """
+        ...
+
+
+# === REDUCER NODE PROTOCOLS ===
+
+
+class ProtocolMemoryConsolidator(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for memory consolidation and deduplication (Reducer node).
+    
+    Consolidates similar memories, removes duplicates while preserving
+    provenance, and merges related memory contexts.
+    """
+    
+    @abstractmethod
+    async def consolidate_memories(
+        self,
+        request: ConsolidationRequest,
+    ) -> NodeResult[ConsolidationResponse]:
+        """
+        Consolidate similar memories into unified representations.
+        
+        Args:
+            request: Consolidation request with consolidation criteria
+            
+        Returns:
+            NodeResult with ConsolidationResponse containing consolidation results
+        """
+        ...
+    
+    @abstractmethod
+    async def deduplicate_memories(
+        self,
+        request: DeduplicationRequest,
+    ) -> NodeResult[DeduplicationResponse]:
+        """
+        Remove duplicate memories while preserving provenance.
+        
+        Args:
+            request: Deduplication request with deduplication parameters
+            
+        Returns:
+            NodeResult with DeduplicationResponse containing deduplication results
+        """
+        ...
+    
+    @abstractmethod
+    async def merge_memory_contexts(
+        self,
+        request: ContextMergeRequest,
+    ) -> NodeResult[ContextMergeResponse]:
+        """
+        Merge related memory contexts.
+        
+        Args:
+            request: Context merge request with merge criteria
+            
+        Returns:
+            NodeResult with ContextMergeResponse containing merge results
+        """
+        ...
+    
+    @abstractmethod
+    async def detect_conflicts(
+        self,
+        memories: List[MemoryRecord],
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelResultCollection]:
+        """
+        Detect conflicts between memory records.
+        
+        Args:
+            memories: List of memory records to analyze
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with list of detected conflicts
+        """
+        ...
+
+
+class ProtocolMemoryAggregator(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for memory aggregation and summarization (Reducer node).
+    
+    Aggregates memories by criteria, creates summaries of memory clusters,
+    and generates statistical analysis of memory usage.
+    """
+    
+    @abstractmethod
+    async def aggregate_memories(
+        self,
+        request: AggregationRequest,
+    ) -> NodeResult[AggregationResponse]:
+        """
+        Aggregate memories by temporal or semantic criteria.
+        
+        Args:
+            request: Aggregation request with aggregation parameters
+            
+        Returns:
+            NodeResult with AggregationResponse containing aggregated data
+        """
+        ...
+    
+    @abstractmethod
+    async def summarize_memory_clusters(
+        self,
+        request: SummarizationRequest,
+    ) -> NodeResult[SummarizationResponse]:
+        """
+        Create summaries of memory clusters.
+        
+        Args:
+            request: Summarization request with cluster data
+            
+        Returns:
+            NodeResult with SummarizationResponse containing cluster summaries
+        """
+        ...
+    
+    @abstractmethod
+    async def generate_memory_statistics(
+        self,
+        request: StatisticsRequest,
+    ) -> NodeResult[StatisticsResponse]:
+        """
+        Generate statistical analysis of memory usage.
+        
+        Args:
+            request: Statistics request with analysis parameters
+            
+        Returns:
+            NodeResult with StatisticsResponse containing usage statistics
+        """
+        ...
+    
+    @abstractmethod
+    async def create_memory_views(
+        self,
+        view_definition: ModelConfiguration,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Create aggregated views of memory data.
+        
+        Args:
+            view_definition: Definition of the view to create
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with created view data
+        """
+        ...
+
+
+class ProtocolMemoryOptimizer(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for memory performance optimization (Reducer node).
+    
+    Optimizes memory storage layout, compresses memories while preserving
+    semantic content, and optimizes retrieval performance.
+    """
+    
+    @abstractmethod
+    async def optimize_memory_layout(
+        self,
+        request: LayoutOptimizationRequest,
+    ) -> NodeResult[LayoutOptimizationResponse]:
+        """
+        Optimize memory storage layout for performance.
+        
+        Args:
+            request: Layout optimization request with optimization parameters
+            
+        Returns:
+            NodeResult with LayoutOptimizationResponse containing optimization results
+        """
+        ...
+    
+    @abstractmethod
+    async def compress_memories(
+        self,
+        request: CompressionRequest,
+    ) -> NodeResult[CompressionResponse]:
+        """
+        Compress memories while preserving semantic content.
+        
+        Args:
+            request: Compression request with compression parameters
+            
+        Returns:
+            NodeResult with CompressionResponse containing compression results
+        """
+        ...
+    
+    @abstractmethod
+    async def optimize_retrieval_paths(
+        self,
+        request: RetrievalOptimizationRequest,
+    ) -> NodeResult[RetrievalOptimizationResponse]:
+        """
+        Optimize memory retrieval performance.
+        
+        Args:
+            request: Retrieval optimization request with optimization parameters
+            
+        Returns:
+            NodeResult with RetrievalOptimizationResponse containing optimization results
+        """
+        ...
+    
+    @abstractmethod
+    async def analyze_performance(
+        self,
+        time_window: datetime,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Analyze memory system performance over a time window.
+        
+        Args:
+            time_window: Time window for performance analysis
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with performance analysis results
+        """
+        ...
+
+
+# === ORCHESTRATOR NODE PROTOCOLS ===
+
+
+class ProtocolWorkflowCoordinator(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for workflow coordination and execution (Orchestrator node).
+    
+    Executes complex memory workflows, coordinates parallel operations,
+    and manages workflow execution state and recovery.
+    """
+    
+    @abstractmethod
+    async def execute_memory_workflow(
+        self,
+        request: WorkflowExecutionRequest,
+    ) -> NodeResult[WorkflowExecutionResponse]:
+        """
+        Execute complex memory workflows.
+        
+        Args:
+            request: Workflow execution request with workflow definition
+            
+        Returns:
+            NodeResult with WorkflowExecutionResponse containing execution results
+        """
+        ...
+    
+    @abstractmethod
+    async def coordinate_parallel_operations(
+        self,
+        request: ParallelCoordinationRequest,
+    ) -> NodeResult[ParallelCoordinationResponse]:
+        """
+        Coordinate parallel memory operations.
+        
+        Args:
+            request: Parallel coordination request with operation definitions
+            
+        Returns:
+            NodeResult with ParallelCoordinationResponse containing coordination results
+        """
+        ...
+    
+    @abstractmethod
+    async def manage_workflow_state(
+        self,
+        request: WorkflowStateRequest,
+    ) -> NodeResult[WorkflowStateResponse]:
+        """
+        Manage workflow execution state and recovery.
+        
+        Args:
+            request: Workflow state request with state management operations
+            
+        Returns:
+            NodeResult with WorkflowStateResponse containing state management results
+        """
+        ...
+    
+    @abstractmethod
+    async def monitor_workflow_progress(
+        self,
+        workflow_id: UUID,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Monitor the progress of a running workflow.
+        
+        Args:
+            workflow_id: ID of the workflow to monitor
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with workflow progress information
+        """
+        ...
+
+
+class ProtocolAgentCoordinator(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for cross-agent coordination and communication (Orchestrator node).
+    
+    Coordinates memory operations across multiple agents, broadcasts memory
+    updates, and synchronizes agent state.
+    """
+    
+    @abstractmethod
+    async def coordinate_agents(
+        self,
+        request: AgentCoordinationRequest,
+    ) -> NodeResult[AgentCoordinationResponse]:
+        """
+        Coordinate memory operations across multiple agents.
+        
+        Args:
+            request: Agent coordination request with coordination parameters
+            
+        Returns:
+            NodeResult with AgentCoordinationResponse containing coordination results
+        """
+        ...
+    
+    @abstractmethod
+    async def broadcast_memory_updates(
+        self,
+        request: BroadcastRequest,
+    ) -> NodeResult[BroadcastResponse]:
+        """
+        Broadcast memory updates to subscribed agents.
+        
+        Args:
+            request: Broadcast request with update information
+            
+        Returns:
+            NodeResult with BroadcastResponse containing broadcast results
+        """
+        ...
+    
+    @abstractmethod
+    async def synchronize_agent_state(
+        self,
+        request: StateSynchronizationRequest,
+    ) -> NodeResult[StateSynchronizationResponse]:
+        """
+        Synchronize memory state across agents.
+        
+        Args:
+            request: State synchronization request with synchronization parameters
+            
+        Returns:
+            NodeResult with StateSynchronizationResponse containing sync results
+        """
+        ...
+    
+    @abstractmethod
+    async def register_agent(
+        self,
+        agent_id: UUID,
+        agent_capabilities: ModelMetadata,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[bool]:
+        """
+        Register an agent with the coordination system.
+        
+        Args:
+            agent_id: Unique identifier for the agent
+            agent_capabilities: Dictionary describing agent capabilities
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult indicating registration success/failure
+        """
+        ...
+
+
+class ProtocolMemoryOrchestrator(ProtocolMemoryOperations, Protocol):
+    """
+    Protocol for high-level memory system orchestration (Orchestrator node).
+    
+    Orchestrates complete memory lifecycle management, manages quotas and limits,
+    and coordinates memory migrations between storage systems.
+    """
+    
+    @abstractmethod
+    async def orchestrate_memory_lifecycle(
+        self,
+        request: LifecycleOrchestrationRequest,
+    ) -> NodeResult[LifecycleOrchestrationResponse]:
+        """
+        Orchestrate complete memory lifecycle management.
+        
+        Args:
+            request: Lifecycle orchestration request with lifecycle parameters
+            
+        Returns:
+            NodeResult with LifecycleOrchestrationResponse containing lifecycle results
+        """
+        ...
+    
+    @abstractmethod
+    async def manage_memory_quotas(
+        self,
+        request: QuotaManagementRequest,
+    ) -> NodeResult[QuotaManagementResponse]:
+        """
+        Manage memory usage quotas and limits.
+        
+        Args:
+            request: Quota management request with quota parameters
+            
+        Returns:
+            NodeResult with QuotaManagementResponse containing quota management results
+        """
+        ...
+    
+    @abstractmethod
+    async def coordinate_memory_migrations(
+        self,
+        request: MigrationCoordinationRequest,
+    ) -> NodeResult[MigrationCoordinationResponse]:
+        """
+        Coordinate memory migrations between storage systems.
+        
+        Args:
+            request: Migration coordination request with migration parameters
+            
+        Returns:
+            NodeResult with MigrationCoordinationResponse containing migration results
+        """
+        ...
+    
+    @abstractmethod
+    async def get_system_status(
+        self,
+        correlation_id: Optional[UUID] = None,
+    ) -> NodeResult[ModelMetadata]:
+        """
+        Get comprehensive memory system status.
+        
+        Args:
+            correlation_id: Request correlation ID
+            
+        Returns:
+            NodeResult with system status information
+        """
+        ...
\ No newline at end of file
diff --git a/src/omnimemory/protocols/data_models.py b/src/omnimemory/protocols/data_models.py
new file mode 100644
index 0000000..b7e03ff
--- /dev/null
+++ b/src/omnimemory/protocols/data_models.py
@@ -0,0 +1,988 @@
+"""
+Data Models for OmniMemory ONEX Architecture
+
+This module contains all Pydantic data models used throughout the OmniMemory system,
+following ONEX contract-driven development patterns with strong typing and validation.
+
+All models support monadic patterns with NodeResult composition and provide
+comprehensive validation, serialization, and observability features.
+"""
+
+from __future__ import annotations
+
+from datetime import datetime
+from enum import Enum
+from typing import Optional
+from uuid import UUID, uuid4
+
+from pydantic import BaseModel, ConfigDict, Field
+
+from ..models.foundation import (
+    ModelStringList,
+    ModelOptionalStringList,
+    ModelMetadata,
+    ModelStructuredData,
+    ModelConfiguration,
+    ModelEventCollection,
+    ModelResultCollection,
+    convert_dict_to_metadata,
+    convert_list_to_string_list,
+)
+
+
+# === ENUMS ===
+
+
+class OperationStatus(str, Enum):
+    """Status of memory operations."""
+    SUCCESS = "success"
+    PARTIAL_SUCCESS = "partial_success"  
+    FAILURE = "failure"
+    TIMEOUT = "timeout"
+    CANCELLED = "cancelled"
+
+
+class ContentType(str, Enum):
+    """Type of memory content."""
+    TEXT = "text"
+    JSON = "json"
+    BINARY = "binary"
+    IMAGE = "image"
+    AUDIO = "audio"
+    VIDEO = "video"
+    STRUCTURED_DATA = "structured_data"
+
+
+class MemoryPriority(str, Enum):
+    """Memory priority levels."""
+    CRITICAL = "critical"
+    HIGH = "high"
+    NORMAL = "normal"
+    LOW = "low"
+    ARCHIVE = "archive"
+
+
+class AccessLevel(str, Enum):
+    """Memory access control levels."""
+    PUBLIC = "public"
+    INTERNAL = "internal"
+    RESTRICTED = "restricted"
+    CONFIDENTIAL = "confidential"
+    SECRET = "secret"
+
+
+class IndexingStatus(str, Enum):
+    """Memory indexing status."""
+    PENDING = "pending"
+    IN_PROGRESS = "in_progress"
+    COMPLETED = "completed"
+    FAILED = "failed"
+    SKIPPED = "skipped"
+
+
+# === BASE MODELS ===
+
+
+class BaseMemoryModel(BaseModel):
+    """Base model for all OmniMemory data structures."""
+    
+    model_config = ConfigDict(
+        # ONEX compliance settings
+        str_strip_whitespace=True,
+        validate_assignment=True,
+        validate_default=True,
+        extra="forbid",
+        frozen=False,
+        # Performance settings
+        use_enum_values=True,
+        arbitrary_types_allowed=False,
+        # Serialization settings
+        ser_json_bytes="base64",
+        ser_json_timedelta="float",
+    )
+
+
+class UserContext(BaseMemoryModel):
+    """User context and permissions for memory operations."""
+
+    user_id: UUID = Field(description="Unique user identifier")
+    agent_id: UUID = Field(description="Agent performing the operation")
+    session_id: Optional[UUID] = Field(None, description="Session identifier")
+    permissions: ModelStringList = Field(
+        default_factory=ModelStringList,
+        description="User permissions for memory operations"
+    )
+    access_level: AccessLevel = Field(
+        AccessLevel.INTERNAL,
+        description="User's maximum access level"
+    )
+    metadata: ModelMetadata = Field(
+        default_factory=ModelMetadata,
+        description="Additional user context metadata"
+    )
+
+
+class StoragePreferences(BaseMemoryModel):
+    """Storage location and durability preferences."""
+    
+    storage_tier: str = Field(
+        "standard",
+        description="Storage tier preference (hot/warm/cold/archive)"
+    )
+    durability_level: str = Field(
+        "standard",
+        description="Durability level (standard/high/critical)"
+    )
+    replication_factor: int = Field(
+        1,
+        ge=1,
+        le=10,
+        description="Number of replicas to maintain"
+    )
+    encryption_required: bool = Field(
+        True,
+        description="Whether encryption is required"
+    )
+    geographic_preference: Optional[str] = Field(
+        None,
+        description="Geographic storage preference"
+    )
+    retention_policy: Optional[str] = Field(
+        None,
+        description="Data retention policy identifier"
+    )
+
+
+class SearchFilters(BaseMemoryModel):
+    """Filters for memory search operations."""
+    
+    content_types: Optional[List[ContentType]] = Field(
+        None,
+        description="Filter by content types"
+    )
+    priority_levels: Optional[List[MemoryPriority]] = Field(
+        None,
+        description="Filter by priority levels"
+    )
+    access_levels: Optional[List[AccessLevel]] = Field(
+        None,
+        description="Filter by access levels"
+    )
+    tags: Optional[ModelOptionalStringList] = Field(
+        None,
+        description="Filter by tags (AND logic)"
+    )
+    source_agents: Optional[ModelOptionalStringList] = Field(
+        None,
+        description="Filter by source agents"
+    )
+    date_range_start: Optional[datetime] = Field(
+        None,
+        description="Filter by creation date (start)"
+    )
+    date_range_end: Optional[datetime] = Field(
+        None,
+        description="Filter by creation date (end)"
+    )
+    has_embeddings: Optional[bool] = Field(
+        None,
+        description="Filter by embedding availability"
+    )
+
+
+class SearchResult(BaseMemoryModel):
+    """Individual search result with scoring."""
+    
+    memory_id: UUID = Field(description="Memory identifier")
+    similarity_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Similarity score (0.0 to 1.0)"
+    )
+    relevance_score: float = Field(
+        ge=0.0,
+        le=1.0,
+        description="Relevance score (0.0 to 1.0)"
+    )
+    memory_record: Optional["MemoryRecord"] = Field(
+        None,
+        description="Full memory record (if requested)"
+    )
+    highlight_snippets: ModelStringList = Field(
+        default_factory=ModelStringList,
+        description="Text snippets with search term highlights"
+    )
+    match_metadata: ModelMetadata = Field(
+        default_factory=ModelMetadata,
+        description="Additional match information"
+    )
+
+
+# === BASE REQUEST/RESPONSE MODELS ===
+
+
+class BaseMemoryRequest(BaseMemoryModel):
+    """Base request schema for all memory operations."""
+    
+    correlation_id: UUID = Field(
+        default_factory=uuid4,
+        description="Correlation ID for request tracking"
+    )
+    timestamp: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="Request timestamp"
+    )
+    user_context: Optional[UserContext] = Field(
+        None,
+        description="User context and permissions"
+    )
+    timeout_ms: int = Field(
+        30000,
+        ge=100,
+        le=300000,
+        description="Request timeout in milliseconds"
+    )
+    metadata: ModelMetadata = Field(default_factory=ModelMetadata,
+        description="Additional request metadata"
+    )
+
+
+class BaseMemoryResponse(BaseMemoryModel):
+    """Base response schema for all memory operations."""
+    
+    correlation_id: UUID = Field(description="Correlation ID matching request")
+    status: OperationStatus = Field(description="Operation execution status")
+    timestamp: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="Response timestamp"
+    )
+    execution_time_ms: int = Field(
+        ge=0,
+        description="Execution time in milliseconds"
+    )
+    provenance: ModelStringList = Field(default_factory=ModelStringList,
+        description="Operation provenance chain"
+    )
+    trust_score: float = Field(
+        1.0,
+        ge=0.0,
+        le=1.0,
+        description="Trust score (0.0 to 1.0)"
+    )
+    metadata: ModelMetadata = Field(default_factory=ModelMetadata,
+        description="Additional response metadata"
+    )
+    warnings: ModelStringList = Field(default_factory=ModelStringList,
+        description="Non-fatal warnings"
+    )
+    events: ModelResultCollection = Field(default_factory=ModelResultCollection,
+        description="Operation events for observability"
+    )
+
+
+# === CORE DATA MODELS ===
+
+
+class MemoryRecord(BaseMemoryModel):
+    """Core memory record with ONEX compliance."""
+    
+    memory_id: UUID = Field(
+        default_factory=uuid4,
+        description="Unique memory identifier"
+    )
+    content: str = Field(
+        description="Memory content",
+        max_length=1048576  # 1MB max content
+    )
+    content_type: ContentType = Field(description="Type of memory content")
+    content_hash: Optional[str] = Field(
+        None,
+        description="SHA-256 hash of content for integrity"
+    )
+    embedding: Optional[List[float]] = Field(
+        None,
+        description="Vector embedding for semantic search",
+        min_length=768,
+        max_length=4096
+    )
+    embedding_model: Optional[str] = Field(
+        None,
+        description="Model used to generate embedding"
+    )
+    tags: ModelStringList = Field(default_factory=ModelStringList,
+        description="Memory tags for categorization",
+        max_length=100
+    )
+    priority: MemoryPriority = Field(
+        MemoryPriority.NORMAL,
+        description="Memory priority level"
+    )
+    created_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="Creation timestamp"
+    )
+    updated_at: datetime = Field(
+        default_factory=datetime.utcnow,
+        description="Last update timestamp"
+    )
+    expires_at: Optional[datetime] = Field(
+        None,
+        description="Expiration timestamp (for temporal memory)"
+    )
+    provenance: ModelStringList = Field(default_factory=ModelStringList,
+        description="Memory provenance chain"
+    )
+    source_agent: str = Field(description="Agent that created this memory")
+    related_memories: List[UUID] = Field(
+        default_factory=list,
+        description="Related memory identifiers"
+    )
+    access_level: AccessLevel = Field(
+        AccessLevel.INTERNAL,
+        description="Memory access control level"
+    )
+    storage_location: Optional[str] = Field(
+        None,
+        description="Physical storage location"
+    )
+    index_status: IndexingStatus = Field(
+        IndexingStatus.PENDING,
+        description="Indexing status for search"
+    )
+    quality_score: float = Field(
+        1.0,
+        ge=0.0,
+        le=1.0,
+        description="Quality score based on content analysis"
+    )
+    usage_count: int = Field(
+        0,
+        ge=0,
+        description="Number of times this memory has been accessed"
+    )
+    last_accessed: Optional[datetime] = Field(
+        None,
+        description="Last access timestamp"
+    )
+
+
+# === MEMORY OPERATION REQUESTS/RESPONSES ===
+
+
+class MemoryStoreRequest(BaseMemoryRequest):
+    """Request to store memory."""
+    
+    memory: MemoryRecord = Field(description="Memory record to store")
+    storage_preferences: Optional[StoragePreferences] = Field(
+        None,
+        description="Storage location and durability preferences"
+    )
+    generate_embedding: bool = Field(
+        True,
+        description="Whether to generate vector embedding"
+    )
+    embedding_model: Optional[str] = Field(
+        None,
+        description="Specific embedding model to use"
+    )
+    index_immediately: bool = Field(
+        True,
+        description="Whether to index for search immediately"
+    )
+
+
+class MemoryStoreResponse(BaseMemoryResponse):
+    """Response from memory store operation."""
+    
+    memory_id: UUID = Field(description="Generated/confirmed memory identifier")
+    storage_location: str = Field(description="Actual storage location")
+    indexing_status: IndexingStatus = Field(description="Indexing completion status")
+    embedding_generated: bool = Field(description="Whether embedding was generated")
+    duplicate_detected: bool = Field(
+        False,
+        description="Whether a duplicate was detected"
+    )
+    storage_size_bytes: int = Field(
+        ge=0,
+        description="Storage size in bytes"
+    )
+
+
+class MemoryRetrieveRequest(BaseMemoryRequest):
+    """Request to retrieve memory by ID."""
+    
+    memory_id: UUID = Field(description="Memory identifier to retrieve")
+    include_embedding: bool = Field(
+        False,
+        description="Include vector embedding in response"
+    )
+    include_related: bool = Field(
+        False,
+        description="Include related memories"
+    )
+    related_depth: int = Field(
+        1,
+        ge=1,
+        le=5,
+        description="Depth of related memory traversal"
+    )
+
+
+class MemoryRetrieveResponse(BaseMemoryResponse):
+    """Response from memory retrieve operation."""
+    
+    memory: Optional[MemoryRecord] = Field(description="Retrieved memory record")
+    related_memories: List[MemoryRecord] = Field(
+        default_factory=list,
+        description="Related memory records (if requested)"
+    )
+    cache_hit: bool = Field(description="Whether result came from cache")
+
+
+class MemoryDeleteRequest(BaseMemoryRequest):
+    """Request to delete memory."""
+    
+    memory_id: UUID = Field(description="Memory identifier to delete")
+    soft_delete: bool = Field(
+        True,
+        description="Whether to perform soft delete (preserving audit trail)"
+    )
+    reason: Optional[str] = Field(
+        None,
+        description="Reason for deletion"
+    )
+
+
+class MemoryDeleteResponse(BaseMemoryResponse):
+    """Response from memory delete operation."""
+    
+    memory_id: UUID = Field(description="Deleted memory identifier")
+    soft_deleted: bool = Field(description="Whether soft delete was performed")
+    backup_location: Optional[str] = Field(
+        None,
+        description="Location of backup (if created)"
+    )
+
+
+# === SEARCH OPERATION REQUESTS/RESPONSES ===
+
+
+class SemanticSearchRequest(BaseMemoryRequest):
+    """Request for semantic similarity search."""
+    
+    query: str = Field(
+        description="Search query text",
+        min_length=1,
+        max_length=10000
+    )
+    limit: int = Field(
+        10,
+        ge=1,
+        le=1000,
+        description="Maximum number of results"
+    )
+    similarity_threshold: float = Field(
+        0.7,
+        ge=0.0,
+        le=1.0,
+        description="Minimum similarity score"
+    )
+    filters: Optional[SearchFilters] = Field(
+        None,
+        description="Additional search filters"
+    )
+    include_embeddings: bool = Field(
+        False,
+        description="Include embeddings in response"
+    )
+    include_content: bool = Field(
+        True,
+        description="Include full content in results"
+    )
+    highlight_matches: bool = Field(
+        True,
+        description="Highlight search terms in content"
+    )
+    embedding_model: Optional[str] = Field(
+        None,
+        description="Specific embedding model for query"
+    )
+
+
+class SemanticSearchResponse(BaseMemoryResponse):
+    """Response from semantic search."""
+    
+    results: List[SearchResult] = Field(description="Search results with scores")
+    total_matches: int = Field(
+        ge=0,
+        description="Total number of matches found"
+    )
+    search_time_ms: int = Field(
+        ge=0,
+        description="Search execution time"
+    )
+    index_version: str = Field(description="Search index version used")
+    query_embedding: Optional[List[float]] = Field(
+        None,
+        description="Query embedding used for search"
+    )
+
+
+class TemporalSearchRequest(BaseMemoryRequest):
+    """Request for time-based memory retrieval."""
+    
+    time_range_start: Optional[datetime] = Field(
+        None,
+        description="Start of time range"
+    )
+    time_range_end: Optional[datetime] = Field(
+        None,
+        description="End of time range"
+    )
+    temporal_decay_factor: float = Field(
+        1.0,
+        ge=0.0,
+        le=1.0,
+        description="Temporal decay factor for scoring"
+    )
+    limit: int = Field(
+        10,
+        ge=1,
+        le=1000,
+        description="Maximum number of results"
+    )
+    filters: Optional[SearchFilters] = Field(
+        None,
+        description="Additional search filters"
+    )
+    sort_by: str = Field(
+        "relevance",
+        description="Sort order (relevance/created_at/updated_at)"
+    )
+
+
+class TemporalSearchResponse(BaseMemoryResponse):
+    """Response from temporal search."""
+    
+    results: List[SearchResult] = Field(description="Time-filtered search results")
+    total_matches: int = Field(
+        ge=0,
+        description="Total number of matches in time range"
+    )
+    time_range_coverage: Dict[str, int] = Field(
+        default_factory=dict,
+        description="Distribution of matches across time periods"
+    )
+
+
+class ContextualSearchRequest(BaseMemoryRequest):
+    """Request for context-aware memory retrieval."""
+    
+    context: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Context parameters for search")
+    context_weight: float = Field(
+        0.5,
+        ge=0.0,
+        le=1.0,
+        description="Weight of context vs content similarity"
+    )
+    limit: int = Field(
+        10,
+        ge=1,
+        le=1000,
+        description="Maximum number of results"
+    )
+    filters: Optional[SearchFilters] = Field(
+        None,
+        description="Additional search filters"
+    )
+
+
+class ContextualSearchResponse(BaseMemoryResponse):
+    """Response from contextual search."""
+    
+    results: List[SearchResult] = Field(description="Context-matched results")
+    context_analysis: ModelMetadata = Field(default_factory=ModelMetadata,
+        description="Analysis of context matching"
+    )
+
+
+# === PLACEHOLDER MODELS FOR COMPLEX OPERATIONS ===
+# These would be fully implemented based on specific requirements
+
+
+class PersistenceRequest(BaseMemoryRequest):
+    """Request for memory persistence operations."""
+    persistence_type: str = Field(description="Type of persistence operation")
+    target_storage: str = Field(description="Target storage system")
+    options: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class PersistenceResponse(BaseMemoryResponse):
+    """Response from persistence operations."""
+    persistence_id: UUID = Field(description="Persistence operation ID")
+    storage_location: str = Field(description="Final storage location")
+
+
+class BackupRequest(BaseMemoryRequest):
+    """Request for memory backup operations."""
+    backup_type: str = Field(description="Type of backup")
+    target_location: str = Field(description="Backup target location")
+    options: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class BackupResponse(BaseMemoryResponse):
+    """Response from backup operations."""
+    backup_id: UUID = Field(description="Backup identifier")
+    backup_location: str = Field(description="Backup storage location")
+
+
+class RestoreRequest(BaseMemoryRequest):
+    """Request for memory restore operations."""
+    backup_id: UUID = Field(description="Backup to restore from")
+    restore_options: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class RestoreResponse(BaseMemoryResponse):
+    """Response from restore operations."""
+    restored_memories: int = Field(description="Number of memories restored")
+    restore_location: str = Field(description="Restore target location")
+
+
+# Intelligence Processing Models
+class IntelligenceProcessRequest(BaseMemoryRequest):
+    """Request for intelligence processing."""
+    raw_data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Raw intelligence data")
+    processing_options: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class IntelligenceProcessResponse(BaseMemoryResponse):
+    """Response from intelligence processing."""
+    processed_data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Processed intelligence data")
+    insights: ModelResultCollection = Field(default_factory=ModelResultCollection)
+
+
+class PatternAnalysisRequest(BaseMemoryRequest):
+    """Request for pattern analysis."""
+    data_set: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Data set to analyze")
+    analysis_type: str = Field(description="Type of pattern analysis")
+
+
+class PatternAnalysisResponse(BaseMemoryResponse):
+    """Response from pattern analysis."""
+    patterns: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Discovered patterns")
+    confidence_scores: List[float] = Field(description="Pattern confidence scores")
+
+
+class InsightExtractionRequest(BaseMemoryRequest):
+    """Request for insight extraction."""
+    processed_data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Processed data to extract insights from")
+    extraction_criteria: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class InsightExtractionResponse(BaseMemoryResponse):
+    """Response from insight extraction."""
+    insights: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Extracted insights")
+    insight_scores: List[float] = Field(description="Insight relevance scores")
+
+
+# Semantic Analysis Models
+class SemanticAnalysisRequest(BaseMemoryRequest):
+    """Request for semantic analysis."""
+    content: str = Field(description="Content to analyze")
+    analysis_depth: str = Field("standard", description="Depth of analysis")
+
+
+class SemanticAnalysisResponse(BaseMemoryResponse):
+    """Response from semantic analysis."""
+    semantic_features: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Semantic features")
+    relationships: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Semantic relationships")
+
+
+class EmbeddingRequest(BaseMemoryRequest):
+    """Request for vector embedding generation."""
+    text: str = Field(description="Text to embed")
+    model: Optional[str] = Field(None, description="Embedding model to use")
+
+
+class EmbeddingResponse(BaseMemoryResponse):
+    """Response from embedding generation."""
+    embedding: List[float] = Field(description="Generated vector embedding")
+    model_used: str = Field(description="Embedding model used")
+    dimensions: int = Field(description="Embedding dimensions")
+
+
+class SemanticComparisonRequest(BaseMemoryRequest):
+    """Request for semantic comparison."""
+    content_a: str = Field(description="First content to compare")
+    content_b: str = Field(description="Second content to compare")
+    comparison_type: str = Field("similarity", description="Type of comparison")
+
+
+class SemanticComparisonResponse(BaseMemoryResponse):
+    """Response from semantic comparison."""
+    similarity_score: float = Field(description="Semantic similarity score")
+    comparison_details: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Detailed comparison results")
+
+
+# Pattern Recognition Models
+class PatternRecognitionRequest(BaseMemoryRequest):
+    """Request for pattern recognition."""
+    data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Data to analyze for patterns")
+    pattern_types: ModelStringList = Field(default_factory=ModelStringList, description="Types of patterns to look for")
+
+
+class PatternRecognitionResponse(BaseMemoryResponse):
+    """Response from pattern recognition."""
+    recognized_patterns: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Recognized patterns")
+    pattern_confidence: List[float] = Field(description="Pattern confidence scores")
+
+
+class PatternLearningRequest(BaseMemoryRequest):
+    """Request for pattern learning."""
+    training_data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Training data for learning")
+    learning_parameters: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class PatternLearningResponse(BaseMemoryResponse):
+    """Response from pattern learning."""
+    learned_patterns: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Newly learned patterns")
+    learning_metrics: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Learning performance metrics")
+
+
+class PatternPredictionRequest(BaseMemoryRequest):
+    """Request for pattern prediction."""
+    context_data: ModelStructuredData = Field(default_factory=ModelStructuredData, description="Context data for prediction")
+    prediction_horizon: int = Field(description="Prediction time horizon")
+
+
+class PatternPredictionResponse(BaseMemoryResponse):
+    """Response from pattern prediction."""
+    predictions: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Pattern predictions")
+    confidence_intervals: List[Dict[str, float]] = Field(description="Prediction confidence")
+
+
+# Memory Consolidation Models
+class ConsolidationRequest(BaseMemoryRequest):
+    """Request for memory consolidation."""
+    memory_ids: List[UUID] = Field(description="Memories to consolidate")
+    consolidation_strategy: str = Field(description="Consolidation strategy")
+
+
+class ConsolidationResponse(BaseMemoryResponse):
+    """Response from memory consolidation."""
+    consolidated_memory_id: UUID = Field(description="ID of consolidated memory")
+    source_memory_ids: List[UUID] = Field(description="IDs of source memories")
+
+
+class DeduplicationRequest(BaseMemoryRequest):
+    """Request for memory deduplication."""
+    memory_scope: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Scope of deduplication")
+    similarity_threshold: float = Field(0.95, description="Similarity threshold for duplicates")
+
+
+class DeduplicationResponse(BaseMemoryResponse):
+    """Response from memory deduplication."""
+    duplicates_removed: int = Field(description="Number of duplicates removed")
+    duplicate_groups: List[List[UUID]] = Field(description="Groups of duplicate memories")
+
+
+class ContextMergeRequest(BaseMemoryRequest):
+    """Request for memory context merging."""
+    context_ids: List[UUID] = Field(description="Context IDs to merge")
+    merge_strategy: str = Field(description="Context merge strategy")
+
+
+class ContextMergeResponse(BaseMemoryResponse):
+    """Response from context merging."""
+    merged_context_id: UUID = Field(description="ID of merged context")
+    source_context_ids: List[UUID] = Field(description="IDs of source contexts")
+
+
+# Memory Aggregation Models
+class AggregationRequest(BaseMemoryRequest):
+    """Request for memory aggregation."""
+    aggregation_criteria: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Aggregation criteria")
+    aggregation_type: str = Field(description="Type of aggregation")
+
+
+class AggregationResponse(BaseMemoryResponse):
+    """Response from memory aggregation."""
+    aggregated_data: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Aggregated memory data")
+    aggregation_metadata: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Aggregation metadata")
+
+
+class SummarizationRequest(BaseMemoryRequest):
+    """Request for memory summarization."""
+    memory_cluster: List[UUID] = Field(description="Memory cluster to summarize")
+    summarization_level: str = Field("standard", description="Level of summarization")
+
+
+class SummarizationResponse(BaseMemoryResponse):
+    """Response from memory summarization."""
+    summary: str = Field(description="Generated summary")
+    key_points: ModelStringList = Field(default_factory=ModelStringList, description="Key points from cluster")
+
+
+class StatisticsRequest(BaseMemoryRequest):
+    """Request for memory statistics."""
+    statistics_type: ModelStringList = Field(default_factory=ModelStringList, description="Types of statistics to generate")
+    time_window: Optional[Dict[str, datetime]] = Field(None, description="Time window for stats")
+
+
+class StatisticsResponse(BaseMemoryResponse):
+    """Response from memory statistics."""
+    statistics: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Generated statistics")
+    charts_data: Optional[ModelMetadata] = Field(None, description="Data for visualization")
+
+
+# Memory Optimization Models
+class LayoutOptimizationRequest(BaseMemoryRequest):
+    """Request for memory layout optimization."""
+    optimization_target: str = Field(description="Optimization target (speed/space/balance)")
+    memory_scope: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Scope of optimization")
+
+
+class LayoutOptimizationResponse(BaseMemoryResponse):
+    """Response from layout optimization."""
+    optimization_results: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Optimization results")
+    performance_improvement: Dict[str, float] = Field(description="Performance gains")
+
+
+class CompressionRequest(BaseMemoryRequest):
+    """Request for memory compression."""
+    compression_algorithm: str = Field(description="Compression algorithm to use")
+    quality_threshold: float = Field(0.9, description="Minimum quality threshold")
+
+
+class CompressionResponse(BaseMemoryResponse):
+    """Response from memory compression."""
+    compression_ratio: float = Field(description="Achieved compression ratio")
+    quality_retained: float = Field(description="Quality retention score")
+
+
+class RetrievalOptimizationRequest(BaseMemoryRequest):
+    """Request for retrieval optimization."""
+    optimization_target: str = Field(description="Optimization target")
+    query_patterns: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Common query patterns")
+
+
+class RetrievalOptimizationResponse(BaseMemoryResponse):
+    """Response from retrieval optimization."""
+    optimization_applied: ModelStringList = Field(default_factory=ModelStringList, description="Optimizations applied")
+    expected_improvement: Dict[str, float] = Field(description="Expected performance gains")
+
+
+# Workflow Coordination Models
+class WorkflowExecutionRequest(BaseMemoryRequest):
+    """Request for workflow execution."""
+    workflow_definition: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Workflow definition")
+    workflow_parameters: ModelConfiguration = Field(default_factory=ModelConfiguration)
+
+
+class WorkflowExecutionResponse(BaseMemoryResponse):
+    """Response from workflow execution."""
+    workflow_id: UUID = Field(description="Executed workflow ID")
+    execution_results: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Workflow execution results")
+
+
+class ParallelCoordinationRequest(BaseMemoryRequest):
+    """Request for parallel operation coordination."""
+    operations: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Operations to coordinate")
+    coordination_strategy: str = Field(description="Coordination strategy")
+
+
+class ParallelCoordinationResponse(BaseMemoryResponse):
+    """Response from parallel coordination."""
+    coordination_results: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Coordination results")
+    execution_summary: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Overall execution summary")
+
+
+class WorkflowStateRequest(BaseMemoryRequest):
+    """Request for workflow state management."""
+    workflow_id: UUID = Field(description="Workflow ID to manage")
+    state_operation: str = Field(description="State operation (get/set/reset)")
+    state_data: Optional[ModelMetadata] = Field(None, description="State data")
+
+
+class WorkflowStateResponse(BaseMemoryResponse):
+    """Response from workflow state management."""
+    current_state: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Current workflow state")
+    state_history: ModelResultCollection = Field(default_factory=ModelResultCollection, description="State change history")
+
+
+# Agent Coordination Models
+class AgentCoordinationRequest(BaseMemoryRequest):
+    """Request for agent coordination."""
+    agent_ids: List[UUID] = Field(description="Agents to coordinate")
+    coordination_task: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Coordination task definition")
+
+
+class AgentCoordinationResponse(BaseMemoryResponse):
+    """Response from agent coordination."""
+    coordination_plan: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Coordination execution plan")
+    agent_assignments: ModelMetadata = Field(default_factory=ModelMetadata,description="Agent task assignments")
+
+
+class BroadcastRequest(BaseMemoryRequest):
+    """Request for memory update broadcast."""
+    update_type: str = Field(description="Type of update to broadcast")
+    update_data: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Update data to broadcast")
+    target_agents: Optional[List[UUID]] = Field(None, description="Target agents (None = all)")
+
+
+class BroadcastResponse(BaseMemoryResponse):
+    """Response from update broadcast."""
+    broadcast_id: UUID = Field(description="Broadcast operation ID")
+    agents_notified: List[UUID] = Field(description="Agents successfully notified")
+    failed_notifications: List[UUID] = Field(description="Agents that failed to receive update")
+
+
+class StateSynchronizationRequest(BaseMemoryRequest):
+    """Request for agent state synchronization."""
+    agent_ids: List[UUID] = Field(description="Agents to synchronize")
+    synchronization_scope: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Scope of synchronization")
+
+
+class StateSynchronizationResponse(BaseMemoryResponse):
+    """Response from state synchronization."""
+    synchronization_results: ModelMetadata = Field(default_factory=ModelMetadata,description="Sync results per agent")
+    conflicts_resolved: ModelResultCollection = Field(default_factory=ModelResultCollection, description="Conflicts that were resolved")
+
+
+# Memory Orchestration Models
+class LifecycleOrchestrationRequest(BaseMemoryRequest):
+    """Request for memory lifecycle orchestration."""
+    lifecycle_stage: str = Field(description="Lifecycle stage to orchestrate")
+    memory_scope: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Scope of memories to orchestrate")
+
+
+class LifecycleOrchestrationResponse(BaseMemoryResponse):
+    """Response from lifecycle orchestration."""
+    orchestration_plan: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Lifecycle orchestration plan")
+    affected_memories: List[UUID] = Field(description="Memories affected by orchestration")
+
+
+class QuotaManagementRequest(BaseMemoryRequest):
+    """Request for quota management."""
+    quota_type: str = Field(description="Type of quota to manage")
+    quota_parameters: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Quota parameters")
+
+
+class QuotaManagementResponse(BaseMemoryResponse):
+    """Response from quota management."""
+    current_quotas: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Current quota status")
+    quota_adjustments: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Applied quota adjustments")
+
+
+class MigrationCoordinationRequest(BaseMemoryRequest):
+    """Request for memory migration coordination."""
+    migration_plan: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Migration plan")
+    source_storage: str = Field(description="Source storage system")
+    target_storage: str = Field(description="Target storage system")
+
+
+class MigrationCoordinationResponse(BaseMemoryResponse):
+    """Response from migration coordination."""
+    migration_id: UUID = Field(description="Migration operation ID")
+    migration_status: ModelConfiguration = Field(default_factory=ModelConfiguration, description="Migration status and progress")
+
diff --git a/src/omnimemory/protocols/error_models.py b/src/omnimemory/protocols/error_models.py
new file mode 100644
index 0000000..b024c5a
--- /dev/null
+++ b/src/omnimemory/protocols/error_models.py
@@ -0,0 +1,622 @@
+"""
+Error Models and Exception Classes for OmniMemory ONEX Architecture
+
+This module defines comprehensive error handling following ONEX standards,
+including structured error codes, exception chaining, and monadic error patterns
+that integrate with NodeResult for consistent error handling across the system.
+"""
+
+from enum import Enum
+from typing import Optional
+from uuid import UUID
+
+from omnibase_core.core.errors.core_errors import OnexError as BaseOnexError
+from pydantic import BaseModel, Field
+
+from ..models.foundation import ModelMetadata
+
+
+# === ERROR CODES ===
+
+
+class OmniMemoryErrorCode(str, Enum):
+    """Comprehensive error codes for OmniMemory operations."""
+    
+    # Validation Errors (ONEX_OMNIMEMORY_VAL_XXX)
+    INVALID_INPUT = "ONEX_OMNIMEMORY_VAL_001_INVALID_INPUT"
+    SCHEMA_VIOLATION = "ONEX_OMNIMEMORY_VAL_002_SCHEMA_VIOLATION"
+    CONSTRAINT_VIOLATION = "ONEX_OMNIMEMORY_VAL_003_CONSTRAINT_VIOLATION"
+    MISSING_REQUIRED_FIELD = "ONEX_OMNIMEMORY_VAL_004_MISSING_REQUIRED_FIELD"
+    INVALID_FORMAT = "ONEX_OMNIMEMORY_VAL_005_INVALID_FORMAT"
+    VALUE_OUT_OF_RANGE = "ONEX_OMNIMEMORY_VAL_006_VALUE_OUT_OF_RANGE"
+    
+    # Storage Errors (ONEX_OMNIMEMORY_STO_XXX)
+    STORAGE_UNAVAILABLE = "ONEX_OMNIMEMORY_STO_001_STORAGE_UNAVAILABLE"
+    QUOTA_EXCEEDED = "ONEX_OMNIMEMORY_STO_002_QUOTA_EXCEEDED"
+    CORRUPTION_DETECTED = "ONEX_OMNIMEMORY_STO_003_CORRUPTION_DETECTED"
+    STORAGE_FULL = "ONEX_OMNIMEMORY_STO_004_STORAGE_FULL"
+    PERSISTENCE_FAILED = "ONEX_OMNIMEMORY_STO_005_PERSISTENCE_FAILED"
+    BACKUP_FAILED = "ONEX_OMNIMEMORY_STO_006_BACKUP_FAILED"
+    RESTORE_FAILED = "ONEX_OMNIMEMORY_STO_007_RESTORE_FAILED"
+    STORAGE_TIMEOUT = "ONEX_OMNIMEMORY_STO_008_STORAGE_TIMEOUT"
+    CONNECTION_FAILED = "ONEX_OMNIMEMORY_STO_009_CONNECTION_FAILED"
+    TRANSACTION_FAILED = "ONEX_OMNIMEMORY_STO_010_TRANSACTION_FAILED"
+    
+    # Retrieval Errors (ONEX_OMNIMEMORY_RET_XXX)
+    MEMORY_NOT_FOUND = "ONEX_OMNIMEMORY_RET_001_MEMORY_NOT_FOUND"
+    INDEX_UNAVAILABLE = "ONEX_OMNIMEMORY_RET_002_INDEX_UNAVAILABLE"
+    ACCESS_DENIED = "ONEX_OMNIMEMORY_RET_003_ACCESS_DENIED"
+    SEARCH_FAILED = "ONEX_OMNIMEMORY_RET_004_SEARCH_FAILED"
+    QUERY_INVALID = "ONEX_OMNIMEMORY_RET_005_QUERY_INVALID"
+    SEARCH_TIMEOUT = "ONEX_OMNIMEMORY_RET_006_SEARCH_TIMEOUT"
+    INDEX_CORRUPTION = "ONEX_OMNIMEMORY_RET_007_INDEX_CORRUPTION"
+    EMBEDDING_UNAVAILABLE = "ONEX_OMNIMEMORY_RET_008_EMBEDDING_UNAVAILABLE"
+    SIMILARITY_COMPUTATION_FAILED = "ONEX_OMNIMEMORY_RET_009_SIMILARITY_COMPUTATION_FAILED"
+    FILTER_INVALID = "ONEX_OMNIMEMORY_RET_010_FILTER_INVALID"
+    
+    # Processing Errors (ONEX_OMNIMEMORY_PRO_XXX)
+    PROCESSING_FAILED = "ONEX_OMNIMEMORY_PRO_001_PROCESSING_FAILED"
+    MODEL_UNAVAILABLE = "ONEX_OMNIMEMORY_PRO_002_MODEL_UNAVAILABLE"
+    RESOURCE_EXHAUSTED = "ONEX_OMNIMEMORY_PRO_003_RESOURCE_EXHAUSTED"
+    ANALYSIS_FAILED = "ONEX_OMNIMEMORY_PRO_004_ANALYSIS_FAILED"
+    EMBEDDING_GENERATION_FAILED = "ONEX_OMNIMEMORY_PRO_005_EMBEDDING_GENERATION_FAILED"
+    PATTERN_RECOGNITION_FAILED = "ONEX_OMNIMEMORY_PRO_006_PATTERN_RECOGNITION_FAILED"
+    SEMANTIC_ANALYSIS_FAILED = "ONEX_OMNIMEMORY_PRO_007_SEMANTIC_ANALYSIS_FAILED"
+    INSIGHT_EXTRACTION_FAILED = "ONEX_OMNIMEMORY_PRO_008_INSIGHT_EXTRACTION_FAILED"
+    MODEL_LOAD_FAILED = "ONEX_OMNIMEMORY_PRO_009_MODEL_LOAD_FAILED"
+    COMPUTATION_TIMEOUT = "ONEX_OMNIMEMORY_PRO_010_COMPUTATION_TIMEOUT"
+    
+    # Coordination Errors (ONEX_OMNIMEMORY_COR_XXX)
+    WORKFLOW_FAILED = "ONEX_OMNIMEMORY_COR_001_WORKFLOW_FAILED"
+    DEADLOCK_DETECTED = "ONEX_OMNIMEMORY_COR_002_DEADLOCK_DETECTED"
+    SYNC_FAILED = "ONEX_OMNIMEMORY_COR_003_SYNC_FAILED"
+    AGENT_UNAVAILABLE = "ONEX_OMNIMEMORY_COR_004_AGENT_UNAVAILABLE"
+    COORDINATION_TIMEOUT = "ONEX_OMNIMEMORY_COR_005_COORDINATION_TIMEOUT"
+    PARALLEL_EXECUTION_FAILED = "ONEX_OMNIMEMORY_COR_006_PARALLEL_EXECUTION_FAILED"
+    STATE_MANAGEMENT_FAILED = "ONEX_OMNIMEMORY_COR_007_STATE_MANAGEMENT_FAILED"
+    BROADCAST_FAILED = "ONEX_OMNIMEMORY_COR_008_BROADCAST_FAILED"
+    MIGRATION_FAILED = "ONEX_OMNIMEMORY_COR_009_MIGRATION_FAILED"
+    ORCHESTRATION_FAILED = "ONEX_OMNIMEMORY_COR_010_ORCHESTRATION_FAILED"
+    
+    # System Errors (ONEX_OMNIMEMORY_SYS_XXX)
+    INTERNAL_ERROR = "ONEX_OMNIMEMORY_SYS_001_INTERNAL_ERROR"
+    CONFIG_ERROR = "ONEX_OMNIMEMORY_SYS_002_CONFIG_ERROR"
+    DEPENDENCY_FAILED = "ONEX_OMNIMEMORY_SYS_003_DEPENDENCY_FAILED"
+    SERVICE_UNAVAILABLE = "ONEX_OMNIMEMORY_SYS_004_SERVICE_UNAVAILABLE"
+    INITIALIZATION_FAILED = "ONEX_OMNIMEMORY_SYS_005_INITIALIZATION_FAILED"
+    SHUTDOWN_FAILED = "ONEX_OMNIMEMORY_SYS_006_SHUTDOWN_FAILED"
+    HEALTH_CHECK_FAILED = "ONEX_OMNIMEMORY_SYS_007_HEALTH_CHECK_FAILED"
+    METRICS_COLLECTION_FAILED = "ONEX_OMNIMEMORY_SYS_008_METRICS_COLLECTION_FAILED"
+    SECURITY_VIOLATION = "ONEX_OMNIMEMORY_SYS_009_SECURITY_VIOLATION"
+    RATE_LIMIT_EXCEEDED = "ONEX_OMNIMEMORY_SYS_010_RATE_LIMIT_EXCEEDED"
+
+
+# === ERROR CATEGORY METADATA ===
+
+
+class ErrorCategoryInfo(BaseModel):
+    """Information about an error category."""
+    
+    prefix: str = Field(description="Error code prefix")
+    description: str = Field(description="Category description")
+    recoverable: bool = Field(description="Whether errors are generally recoverable")
+    default_retry_count: int = Field(3, description="Default retry count")
+    default_backoff_factor: float = Field(2.0, description="Default backoff multiplier")
+
+
+ERROR_CATEGORIES: Dict[str, ErrorCategoryInfo] = {
+    "VALIDATION": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_VAL",
+        description="Input validation errors",
+        recoverable=False,
+        default_retry_count=0,
+        default_backoff_factor=1.0
+    ),
+    "STORAGE": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_STO", 
+        description="Storage system errors",
+        recoverable=True,
+        default_retry_count=3,
+        default_backoff_factor=2.0
+    ),
+    "RETRIEVAL": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_RET",
+        description="Memory retrieval errors",
+        recoverable=True,
+        default_retry_count=2,
+        default_backoff_factor=1.5
+    ),
+    "PROCESSING": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_PRO",
+        description="Intelligence processing errors", 
+        recoverable=True,
+        default_retry_count=2,
+        default_backoff_factor=2.0
+    ),
+    "COORDINATION": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_COR",
+        description="Coordination and workflow errors",
+        recoverable=True,
+        default_retry_count=3,
+        default_backoff_factor=1.5
+    ),
+    "SYSTEM": ErrorCategoryInfo(
+        prefix="ONEX_OMNIMEMORY_SYS",
+        description="System-level errors",
+        recoverable=False,
+        default_retry_count=1,
+        default_backoff_factor=1.0
+    ),
+}
+
+
+def get_error_category(error_code: OmniMemoryErrorCode) -> Optional[ErrorCategoryInfo]:
+    """Get error category information for an error code."""
+    for category_name, category_info in ERROR_CATEGORIES.items():
+        if error_code.value.startswith(category_info.prefix):
+            return category_info
+    return None
+
+
+# === BASE EXCEPTION CLASSES ===
+
+
+class OmniMemoryError(BaseOnexError):
+    """
+    Base exception class for all OmniMemory errors.
+    
+    Extends ONEX BaseOnexError with OmniMemory-specific functionality
+    including error categorization, recovery hints, and monadic integration.
+    """
+    
+    def __init__(
+        self,
+        error_code: OmniMemoryErrorCode,
+        message: str,
+        context: Optional[ModelMetadata] = None,
+        correlation_id: Optional[UUID] = None,
+        cause: Optional[Exception] = None,
+        recovery_hint: Optional[str] = None,
+        retry_after: Optional[int] = None,
+        **kwargs,
+    ):
+        """
+        Initialize OmniMemory error.
+        
+        Args:
+            error_code: Specific error code from OmniMemoryErrorCode
+            message: Human-readable error message
+            context: Additional error context information
+            correlation_id: Request correlation ID for tracing
+            cause: Underlying exception that caused this error
+            recovery_hint: Suggestion for error recovery
+            retry_after: Suggested retry delay in seconds
+            **kwargs: Additional keyword arguments passed to BaseOnexError
+        """
+        # Get error category information
+        category_info = get_error_category(error_code)
+        
+        # Enhance context with category information
+        enhanced_context = context or {}
+        if category_info:
+            enhanced_context.update({
+                "error_category": category_info.prefix.split("_")[-1].lower(),
+                "recoverable": category_info.recoverable,
+                "default_retry_count": category_info.default_retry_count,
+                "default_backoff_factor": category_info.default_backoff_factor,
+            })
+        
+        # Add recovery information
+        if recovery_hint:
+            enhanced_context["recovery_hint"] = recovery_hint
+        if retry_after:
+            enhanced_context["retry_after_seconds"] = retry_after
+        
+        # Initialize base OnexError
+        super().__init__(
+            error_code=error_code.value,
+            message=message,
+            context=enhanced_context,
+            correlation_id=correlation_id,
+            **kwargs,
+        )
+        
+        # Store additional OmniMemory-specific information
+        self.omnimemory_error_code = error_code
+        self.category_info = category_info
+        self.recovery_hint = recovery_hint
+        self.retry_after = retry_after
+        self.cause = cause
+        
+        # Chain the underlying cause if provided
+        if cause:
+            self.__cause__ = cause
+    
+    def is_recoverable(self) -> bool:
+        """Check if this error is generally recoverable."""
+        return self.category_info.recoverable if self.category_info else False
+    
+    def get_retry_count(self) -> int:
+        """Get suggested retry count for this error."""
+        return self.category_info.default_retry_count if self.category_info else 0
+    
+    def get_backoff_factor(self) -> float:
+        """Get suggested backoff factor for retries."""
+        return self.category_info.default_backoff_factor if self.category_info else 1.0
+    
+    def to_dict(self) -> dict[str, str]:
+        """Convert error to dictionary for serialization."""
+        base_dict = {
+            "error_code": self.omnimemory_error_code.value,
+            "message": self.message,
+            "context": self.context,
+            "correlation_id": str(self.correlation_id) if self.correlation_id else None,
+            "recoverable": self.is_recoverable(),
+            "retry_count": self.get_retry_count(),
+            "backoff_factor": self.get_backoff_factor(),
+        }
+        
+        if self.recovery_hint:
+            base_dict["recovery_hint"] = self.recovery_hint
+        if self.retry_after:
+            base_dict["retry_after_seconds"] = self.retry_after
+        if self.cause:
+            base_dict["cause"] = str(self.cause)
+        
+        return base_dict
+
+
+# === CATEGORY-SPECIFIC EXCEPTION CLASSES ===
+
+
+class ValidationError(OmniMemoryError):
+    """Exception for input validation errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        field_name: Optional[str] = None,
+        field_value: Optional[Any] = None,
+        validation_rule: Optional[str] = None,
+        **kwargs,
+    ):
+        # Determine specific validation error code
+        error_code = OmniMemoryErrorCode.INVALID_INPUT
+        if "schema" in message.lower():
+            error_code = OmniMemoryErrorCode.SCHEMA_VIOLATION
+        elif "constraint" in message.lower():
+            error_code = OmniMemoryErrorCode.CONSTRAINT_VIOLATION
+        elif "required" in message.lower():
+            error_code = OmniMemoryErrorCode.MISSING_REQUIRED_FIELD
+        elif "format" in message.lower():
+            error_code = OmniMemoryErrorCode.INVALID_FORMAT
+        elif "range" in message.lower():
+            error_code = OmniMemoryErrorCode.VALUE_OUT_OF_RANGE
+        
+        # Build context with validation details
+        context = kwargs.get("context", {})
+        if field_name:
+            context["field_name"] = field_name
+        if field_value is not None:
+            context["field_value"] = str(field_value)
+        if validation_rule:
+            context["validation_rule"] = validation_rule
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Review and correct the input data according to the schema requirements"
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+class StorageError(OmniMemoryError):
+    """Exception for storage system errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        storage_system: Optional[str] = None,
+        operation: Optional[str] = None,
+        **kwargs,
+    ):
+        # Determine specific storage error code  
+        error_code = OmniMemoryErrorCode.STORAGE_UNAVAILABLE
+        if "quota" in message.lower() or "full" in message.lower():
+            error_code = OmniMemoryErrorCode.QUOTA_EXCEEDED
+        elif "corrupt" in message.lower():
+            error_code = OmniMemoryErrorCode.CORRUPTION_DETECTED
+        elif "persist" in message.lower():
+            error_code = OmniMemoryErrorCode.PERSISTENCE_FAILED
+        elif "backup" in message.lower():
+            error_code = OmniMemoryErrorCode.BACKUP_FAILED
+        elif "restore" in message.lower():
+            error_code = OmniMemoryErrorCode.RESTORE_FAILED
+        elif "timeout" in message.lower():
+            error_code = OmniMemoryErrorCode.STORAGE_TIMEOUT
+        elif "connection" in message.lower():
+            error_code = OmniMemoryErrorCode.CONNECTION_FAILED
+        elif "transaction" in message.lower():
+            error_code = OmniMemoryErrorCode.TRANSACTION_FAILED
+        
+        # Build context with storage details
+        context = kwargs.get("context", {})
+        if storage_system:
+            context["storage_system"] = storage_system
+        if operation:
+            context["operation"] = operation
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Check storage system health and retry with exponential backoff"
+        kwargs["retry_after"] = 5  # Suggest 5 second retry delay
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+class RetrievalError(OmniMemoryError):
+    """Exception for memory retrieval errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        memory_id: Optional[UUID] = None,
+        query: Optional[str] = None,
+        **kwargs,
+    ):
+        # Determine specific retrieval error code
+        error_code = OmniMemoryErrorCode.SEARCH_FAILED
+        if "not found" in message.lower():
+            error_code = OmniMemoryErrorCode.MEMORY_NOT_FOUND
+        elif "index" in message.lower() and "unavailable" in message.lower():
+            error_code = OmniMemoryErrorCode.INDEX_UNAVAILABLE
+        elif "access denied" in message.lower():
+            error_code = OmniMemoryErrorCode.ACCESS_DENIED
+        elif "invalid" in message.lower() and "query" in message.lower():
+            error_code = OmniMemoryErrorCode.QUERY_INVALID
+        elif "timeout" in message.lower():
+            error_code = OmniMemoryErrorCode.SEARCH_TIMEOUT
+        elif "corrupt" in message.lower():
+            error_code = OmniMemoryErrorCode.INDEX_CORRUPTION
+        elif "embedding" in message.lower():
+            error_code = OmniMemoryErrorCode.EMBEDDING_UNAVAILABLE
+        elif "similarity" in message.lower():
+            error_code = OmniMemoryErrorCode.SIMILARITY_COMPUTATION_FAILED
+        elif "filter" in message.lower():
+            error_code = OmniMemoryErrorCode.FILTER_INVALID
+        
+        # Build context with retrieval details
+        context = kwargs.get("context", {})
+        if memory_id:
+            context["memory_id"] = str(memory_id)
+        if query:
+            context["query"] = query
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Verify search parameters and check index health"
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+class ProcessingError(OmniMemoryError):
+    """Exception for intelligence processing errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        processing_stage: Optional[str] = None,
+        model_name: Optional[str] = None,
+        **kwargs,
+    ):
+        # Determine specific processing error code
+        error_code = OmniMemoryErrorCode.PROCESSING_FAILED
+        if "model unavailable" in message.lower():
+            error_code = OmniMemoryErrorCode.MODEL_UNAVAILABLE
+        elif "resource" in message.lower() and "exhaust" in message.lower():
+            error_code = OmniMemoryErrorCode.RESOURCE_EXHAUSTED
+        elif "analysis failed" in message.lower():
+            error_code = OmniMemoryErrorCode.ANALYSIS_FAILED
+        elif "embedding" in message.lower():
+            error_code = OmniMemoryErrorCode.EMBEDDING_GENERATION_FAILED
+        elif "pattern" in message.lower():
+            error_code = OmniMemoryErrorCode.PATTERN_RECOGNITION_FAILED
+        elif "semantic" in message.lower():
+            error_code = OmniMemoryErrorCode.SEMANTIC_ANALYSIS_FAILED
+        elif "insight" in message.lower():
+            error_code = OmniMemoryErrorCode.INSIGHT_EXTRACTION_FAILED
+        elif "model load" in message.lower():
+            error_code = OmniMemoryErrorCode.MODEL_LOAD_FAILED
+        elif "timeout" in message.lower():
+            error_code = OmniMemoryErrorCode.COMPUTATION_TIMEOUT
+        
+        # Build context with processing details
+        context = kwargs.get("context", {})
+        if processing_stage:
+            context["processing_stage"] = processing_stage
+        if model_name:
+            context["model_name"] = model_name
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Check model availability and processing resources"
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+class CoordinationError(OmniMemoryError):
+    """Exception for coordination and workflow errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        workflow_id: Optional[UUID] = None,
+        agent_ids: Optional[List[UUID]] = None,
+        **kwargs,
+    ):
+        # Determine specific coordination error code
+        error_code = OmniMemoryErrorCode.WORKFLOW_FAILED
+        if "deadlock" in message.lower():
+            error_code = OmniMemoryErrorCode.DEADLOCK_DETECTED
+        elif "sync" in message.lower() and "failed" in message.lower():
+            error_code = OmniMemoryErrorCode.SYNC_FAILED
+        elif "agent unavailable" in message.lower():
+            error_code = OmniMemoryErrorCode.AGENT_UNAVAILABLE
+        elif "timeout" in message.lower():
+            error_code = OmniMemoryErrorCode.COORDINATION_TIMEOUT
+        elif "parallel" in message.lower():
+            error_code = OmniMemoryErrorCode.PARALLEL_EXECUTION_FAILED
+        elif "state" in message.lower():
+            error_code = OmniMemoryErrorCode.STATE_MANAGEMENT_FAILED
+        elif "broadcast" in message.lower():
+            error_code = OmniMemoryErrorCode.BROADCAST_FAILED
+        elif "migration" in message.lower():
+            error_code = OmniMemoryErrorCode.MIGRATION_FAILED
+        elif "orchestration" in message.lower():
+            error_code = OmniMemoryErrorCode.ORCHESTRATION_FAILED
+        
+        # Build context with coordination details
+        context = kwargs.get("context", {})
+        if workflow_id:
+            context["workflow_id"] = str(workflow_id)
+        if agent_ids:
+            context["agent_ids"] = [str(aid) for aid in agent_ids]
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Check agent availability and retry coordination"
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+class SystemError(OmniMemoryError):
+    """Exception for system-level errors."""
+    
+    def __init__(
+        self,
+        message: str,
+        system_component: Optional[str] = None,
+        **kwargs,
+    ):
+        # Determine specific system error code
+        error_code = OmniMemoryErrorCode.INTERNAL_ERROR
+        if "config" in message.lower():
+            error_code = OmniMemoryErrorCode.CONFIG_ERROR
+        elif "dependency" in message.lower():
+            error_code = OmniMemoryErrorCode.DEPENDENCY_FAILED
+        elif "service unavailable" in message.lower():
+            error_code = OmniMemoryErrorCode.SERVICE_UNAVAILABLE
+        elif "initialization" in message.lower():
+            error_code = OmniMemoryErrorCode.INITIALIZATION_FAILED
+        elif "shutdown" in message.lower():
+            error_code = OmniMemoryErrorCode.SHUTDOWN_FAILED
+        elif "health check" in message.lower():
+            error_code = OmniMemoryErrorCode.HEALTH_CHECK_FAILED
+        elif "metrics" in message.lower():
+            error_code = OmniMemoryErrorCode.METRICS_COLLECTION_FAILED
+        elif "security" in message.lower():
+            error_code = OmniMemoryErrorCode.SECURITY_VIOLATION
+        elif "rate limit" in message.lower():
+            error_code = OmniMemoryErrorCode.RATE_LIMIT_EXCEEDED
+        
+        # Build context with system details
+        context = kwargs.get("context", {})
+        if system_component:
+            context["system_component"] = system_component
+        
+        kwargs["context"] = context
+        kwargs["recovery_hint"] = "Contact system administrator for system-level issues"
+        
+        super().__init__(error_code=error_code, message=message, **kwargs)
+
+
+# === ERROR UTILITIES ===
+
+
+def wrap_exception(
+    exception: Exception,
+    error_code: OmniMemoryErrorCode,
+    message: Optional[str] = None,
+    **kwargs,
+) -> OmniMemoryError:
+    """
+    Wrap a generic exception in an OmniMemoryError.
+    
+    Args:
+        exception: The original exception to wrap
+        error_code: The OmniMemory error code to use
+        message: Optional custom message (uses exception message if not provided)
+        **kwargs: Additional arguments for OmniMemoryError constructor
+        
+    Returns:
+        OmniMemoryError wrapping the original exception
+    """
+    error_message = message or str(exception)
+    return OmniMemoryError(
+        error_code=error_code,
+        message=error_message,
+        cause=exception,
+        **kwargs,
+    )
+
+
+def chain_errors(
+    primary_error: OmniMemoryError,
+    secondary_error: Exception,
+) -> OmniMemoryError:
+    """
+    Chain a secondary error to a primary OmniMemoryError.
+    
+    Args:
+        primary_error: The primary OmniMemoryError
+        secondary_error: The secondary exception to chain
+        
+    Returns:
+        Updated primary error with chained secondary error
+    """
+    if primary_error.cause is None:
+        primary_error.cause = secondary_error
+        primary_error.__cause__ = secondary_error
+    else:
+        # If there's already a cause, chain it
+        current = primary_error.cause
+        while hasattr(current, '__cause__') and current.__cause__ is not None:
+            current = current.__cause__
+        current.__cause__ = secondary_error
+    
+    return primary_error
+
+
+def create_error_summary(errors: list[OmniMemoryError]) -> dict[str, str]:
+    """
+    Create a summary of multiple errors for reporting.
+    
+    Args:
+        errors: List of OmniMemoryError instances
+        
+    Returns:
+        Dictionary containing error summary statistics
+    """
+    if not errors:
+        return {"total_errors": 0}
+    
+    error_counts = {}
+    category_counts = {}
+    recoverable_count = 0
+    
+    for error in errors:
+        # Count by error code
+        error_code = error.omnimemory_error_code.value
+        error_counts[error_code] = error_counts.get(error_code, 0) + 1
+        
+        # Count by category
+        if error.category_info:
+            category = error.category_info.prefix.split("_")[-1].lower()
+            category_counts[category] = category_counts.get(category, 0) + 1
+        
+        # Count recoverable errors
+        if error.is_recoverable():
+            recoverable_count += 1
+    
+    return {
+        "total_errors": len(errors),
+        "recoverable_errors": recoverable_count,
+        "non_recoverable_errors": len(errors) - recoverable_count,
+        "error_counts_by_code": error_counts,
+        "error_counts_by_category": category_counts,
+        "recovery_rate": recoverable_count / len(errors) if errors else 0.0,
+    }
\ No newline at end of file
diff --git a/src/omnimemory/utils/__init__.py b/src/omnimemory/utils/__init__.py
new file mode 100644
index 0000000..02a80a7
--- /dev/null
+++ b/src/omnimemory/utils/__init__.py
@@ -0,0 +1,173 @@
+"""
+Utility modules for OmniMemory ONEX architecture.
+
+This package provides common utilities used across the OmniMemory system:
+- Retry logic with exponential backoff
+- Resource management with circuit breakers and async context managers
+- Observability with ContextVar correlation tracking
+- Concurrency utilities with priority locks and fair semaphores
+- Health checking with comprehensive dependency monitoring
+- Performance monitoring helpers
+- Common validation patterns
+"""
+
+from .retry_utils import (
+    RetryConfig,
+    RetryAttemptInfo,
+    RetryStatistics,
+    RetryManager,
+    default_retry_manager,
+    retry_decorator,
+    retry_with_backoff,
+    is_retryable_exception,
+    calculate_delay,
+)
+
+from .resource_manager import (
+    CircuitState,
+    CircuitBreakerConfig,
+    CircuitBreakerError,
+    AsyncCircuitBreaker,
+    AsyncResourceManager,
+    resource_manager,
+    with_circuit_breaker,
+    with_semaphore,
+    with_timeout,
+)
+
+from .observability import (
+    TraceLevel,
+    OperationType,
+    CorrelationContext,
+    ObservabilityManager,
+    observability_manager,
+    correlation_context,
+    trace_operation,
+    get_correlation_id,
+    get_request_id,
+    log_with_correlation,
+    inject_correlation_context,
+    inject_correlation_context_async,
+    validate_correlation_id,
+    sanitize_metadata_value,
+)
+
+from .concurrency import (
+    LockPriority,
+    PoolStatus,
+    ConnectionPoolConfig,
+    PriorityLock,
+    FairSemaphore,
+    AsyncConnectionPool,
+    get_priority_lock,
+    get_fair_semaphore,
+    register_connection_pool,
+    get_connection_pool,
+    with_priority_lock,
+    with_fair_semaphore,
+    with_connection_pool,
+)
+
+from .health_manager import (
+    HealthStatus,
+    DependencyType,
+    HealthCheckConfig,
+    HealthCheckResult,
+    HealthCheckManager,
+    health_manager,
+    RateLimiter,
+    create_postgresql_health_check,
+    create_redis_health_check,
+    create_pinecone_health_check,
+)
+
+from .pii_detector import (
+    PIIType,
+    PIIMatch,
+    PIIDetectionResult,
+    PIIDetectorConfig,
+    PIIDetector,
+)
+
+from .error_sanitizer import (
+    SanitizationLevel,
+    ErrorSanitizer,
+)
+
+__all__ = [
+    # Retry utilities
+    "RetryConfig",
+    "RetryAttemptInfo",
+    "RetryStatistics",
+    "RetryManager",
+    "default_retry_manager",
+    "retry_decorator",
+    "retry_with_backoff",
+    "is_retryable_exception",
+    "calculate_delay",
+
+    # Resource management
+    "CircuitState",
+    "CircuitBreakerConfig",
+    "CircuitBreakerError",
+    "AsyncCircuitBreaker",
+    "AsyncResourceManager",
+    "resource_manager",
+    "with_circuit_breaker",
+    "with_semaphore",
+    "with_timeout",
+
+    # Observability
+    "TraceLevel",
+    "OperationType",
+    "CorrelationContext",
+    "ObservabilityManager",
+    "observability_manager",
+    "correlation_context",
+    "trace_operation",
+    "get_correlation_id",
+    "get_request_id",
+    "log_with_correlation",
+    "inject_correlation_context",
+    "inject_correlation_context_async",
+    "validate_correlation_id",
+    "sanitize_metadata_value",
+
+    # Concurrency
+    "LockPriority",
+    "PoolStatus",
+    "ConnectionPoolConfig",
+    "PriorityLock",
+    "FairSemaphore",
+    "AsyncConnectionPool",
+    "get_priority_lock",
+    "get_fair_semaphore",
+    "register_connection_pool",
+    "get_connection_pool",
+    "with_priority_lock",
+    "with_fair_semaphore",
+    "with_connection_pool",
+
+    # Health management
+    "HealthStatus",
+    "DependencyType",
+    "HealthCheckConfig",
+    "HealthCheckResult",
+    "HealthCheckManager",
+    "health_manager",
+    "RateLimiter",
+    "create_postgresql_health_check",
+    "create_redis_health_check",
+    "create_pinecone_health_check",
+
+    # PII Detection
+    "PIIType",
+    "PIIMatch",
+    "PIIDetectionResult",
+    "PIIDetectorConfig",
+    "PIIDetector",
+
+    # Error Sanitization
+    "SanitizationLevel",
+    "ErrorSanitizer",
+]
\ No newline at end of file
